{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:  P. Lewis\n",
    "\n",
    "Date:    Thu 25 Feb 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates the preparation of datasets for BRDF/albedo processing.\n",
    "\n",
    "An example is used where we have *broadband* observation datasets from MERIS, SPOT VGT `['bbdr.meris', 'bbdr.vgt']` and MODIS (Terra and Aqua) `['mod09', 'myd09']`.\n",
    "\n",
    "For testing other constraints, we also have different versions of a climatology (the 'prior') `['prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow']`.\n",
    "\n",
    "For comparison, we also have the results from the GlobAlbedo processing chain `['ga.brdf.nosnow', 'ga.brdf.snow', 'ga.brdf.merge']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory /Users/plewis/QA4ECV_ATBD/data\n"
     ]
    }
   ],
   "source": [
    "# load required libraries: you may need to install netCDF4\n",
    "from defaults import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbdr.meris bbdr.vgt ga.brdf.merge ga.brdf.nosnow ga.brdf.snow mod09 myd09 prior.v2.nosnow prior.v2.snow prior.v2.snownosnow\n"
     ]
    }
   ],
   "source": [
    "datakeys = np.array(['bbdr.meris', 'bbdr.vgt', 'ga.brdf.merge',\\\n",
    "       'ga.brdf.nosnow', 'ga.brdf.snow', 'mod09', 'myd09',\\\n",
    "       'prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow'])\n",
    "# load the datasets into a dictionary in ncdata\n",
    "ncdata = {}\n",
    "for k in datakeys:\n",
    "    print k,\n",
    "    ncdata[k] = load_obj('obj/'+ k + '_s2.0_' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next consider what time period we want to do mapping for.\n",
    "\n",
    "Here, we start from the first date in the `bbdr.vgt` dataset and end on the last date of `mod09`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 1998-04-03 to 2016-01-01 inclusive which gives 6483 days\n"
     ]
    }
   ],
   "source": [
    "d0,d1 = ncdata['bbdr.vgt']['date'][0],ncdata['mod09']['date'][-1]\n",
    "print 'from',d0,'to',d1,'inclusive',\n",
    "ndays = (d1-d0).days + 1\n",
    "print 'which gives',ndays,'days'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the wavebands of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bands = np.array(['VIS','NIR','SW'])\n",
    "nbands = bands.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pull out the parts of the dataset that we want access to, and structure them in convenient forms.\n",
    "\n",
    "For `meris` and `vgt`, this is:\n",
    "\n",
    "    reflectance:\n",
    "        BB\n",
    "        \n",
    "    BRDF kernels:\n",
    "        Isotropic \n",
    "        Kvol_BRDF\n",
    "        Kgeo_BRDF\n",
    "        \n",
    "    Covariance matrix terms:\n",
    "        sig_BB\n",
    "        \n",
    "All of these terms are spectral (i.e. defined for each waveband) (so, `BB_VIS` etc., `Kvol_BRDF_VIS` etc., `sig_BB_VIS_NIR` etc.).\n",
    "\n",
    "Note that Isotropic is all ones (for valid samples), so this is provided during this reading, rather than loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "np.arange(10)[slice(None)]\n",
    "dataset = ncdata['bbdr.%s'%'vgt']\n",
    "tester = np.array(dataset['BB_VIS'])\n",
    "print tester.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pixel row col in dataset\n",
    "r,c = 0,0\n",
    "\n",
    "for m in ['mod09', 'meris','vgt',  'myd09']:\n",
    "    plt.figure(figsize=(15,3))\n",
    "    \n",
    "    # ID the datazet\n",
    "    try:\n",
    "        dataset = ncdata['bbdr.%s'%m]\n",
    "        # these are 3D datasets\n",
    "        sl = (slice(None),r,c)\n",
    "        sVis = '_BRDF_VIS'\n",
    "        sNir = '_BRDF_NIR'\n",
    "        sSw  = '_BRDF_SW'\n",
    "\n",
    "        datatype = 'A'\n",
    "    except:\n",
    "        # these may be 1 D but need to fix\n",
    "        dataset = ncdata[m]\n",
    "        sl = slice(None)\n",
    "        sVis = sNir = sSw = ''\n",
    "        datatype = 'B'\n",
    "         \n",
    "    # pull reflectance data\n",
    "    refl = np.array([np.array(dataset['BB_VIS'])[sl],\n",
    "                     np.array(dataset['BB_NIR'])[sl],\n",
    "                     np.array(dataset['BB_SW'])[sl]])\n",
    "    # identify dodgy values from refl\n",
    "    # these data are shaped (nbands, nsamples)\n",
    "    # If any of the nbands is False, we want to ignore all bands\n",
    "    # so \n",
    "    mask = ((refl>0)*(refl<1)).prod(axis=0).astype(bool)\n",
    "    try:\n",
    "        # assuming dataset['mask'] is True for good data\n",
    "        mask = np.logical_or(np.array(dataset['mask'])[sl],mask)\n",
    "    except:\n",
    "        pass\n",
    "    # easiest to reload now ...\n",
    "    refl = np.array([np.array(dataset['BB_VIS'])[sl][mask],\n",
    "                     np.array(dataset['BB_NIR'])[sl][mask],\n",
    "                     np.array(dataset['BB_SW'])[sl][mask]])\n",
    "\n",
    "    # isotropic\n",
    "    Isotropic = np.ones_like(dataset['Kvol'%sVis])\n",
    "    # kernels\n",
    "    kernels = np.array([[Isotropic[sl][mask],\\\n",
    "                         Isotropic[sl][mask],\\\n",
    "                         Isotropic[sl][mask]],\\\n",
    "                        [np.array(dataset['Kvol'%sVis])[sl][mask],\\\n",
    "                         np.array(dataset['Kvol'%sNir])[sl][mask],\\\n",
    "                         np.array(dataset['Kvol'%sSw])[sl][mask]],\\\n",
    "                        [np.array(dataset['Kgeo'%sVis])[sl][mask],\\\n",
    "                         np.array(dataset['Kgeo'%sNir])[sl][mask],\\\n",
    "                         np.array(dataset['Kgeo'%sSw])[sl][mask]]\\\n",
    "                       ])\n",
    "    # uncertainty\n",
    "    if datatype == 'A':\n",
    "        var     = np.array([[np.array(dataset['sig_BB_VIS_VIS'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_VIS_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_VIS_SW'])[sl][mask]],\\\n",
    "                        [np.array(dataset['sig_BB_VIS_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_SW'])[sl][mask]],\\\n",
    "                        [np.array(dataset['sig_BB_VIS_SW'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_SW'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_SW_SW'])[sl][mask]]\\\n",
    "                       ])    \n",
    "\n",
    "        weight = np.zeros_like(var)\n",
    "        for i in xrange(refl.shape[-1]):\n",
    "            try:\n",
    "                weight[...,i] = np.matrix(var[...,i]).I\n",
    "            except:\n",
    "                pass\n",
    "        del var\n",
    "    elif datatype == 'B':\n",
    "        w1 = [[dataset['weight_BB_VIS_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_NIR_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_VIS']]*len(mask)]\n",
    "        w2 = [[dataset['weight_BB_NIR_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_NIR_NIR']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_NIR']]*len(mask)]\n",
    "        w3 = [[dataset['weight_BB_SW_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_NIR']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_SW']]*len(mask)]\n",
    "        weight = np.array([w1,w2,w3])  \n",
    "\n",
    "    date = dataset['date'][mask]        \n",
    "    \n",
    "    for i in xrange(nbands):\n",
    "        plt.plot(date,refl[i],'+')\n",
    "    plt.ylim(0,.7)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('reflectance')\n",
    "    #plt.legend(loc='best')\n",
    "    plt.title('%s no snow'%m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in ['mod09','myd09']:\n",
    "    dataset = ncdata['%s'%m]\n",
    "    plt.figure(figsize=(15,3))\n",
    "    refl = np.array([dataset['BB_VIS'],dataset['BB_NIR'],dataset['BB_SW']]).squeeze()\n",
    "    refl[refl<=0] = np.nan\n",
    "    \n",
    "    mask = (~np.isnan(refl)).astype(int).prod(axis=0).astype(bool)\n",
    "    \n",
    "    weight = np.array([[dataset['weight_BB_VIS_VIS'],\\\n",
    "                dataset['weight_BB_NIR_VIS'],\\\n",
    "                dataset['weight_BB_SW_VIS']],\\\n",
    "               \\\n",
    "               [dataset['weight_BB_NIR_VIS'],\\\n",
    "                dataset['weight_BB_NIR_NIR'],\\\n",
    "                dataset['weight_BB_SW_NIR']],\\\n",
    "               \\\n",
    "               [dataset['weight_BB_SW_VIS'],\\\n",
    "                dataset['weight_BB_SW_NIR'],\\\n",
    "                dataset['weight_BB_SW_SW']]]).squeeze() / scale\n",
    "        \n",
    "    #print dataset['weight_BB_SW_VIS']\n",
    "    ones = np.ones_like(dataset['Kvol'])\n",
    "    kernels = np.array([[ones,ones,ones],\\\n",
    "                        [dataset['Kvol'],dataset['Kvol'],dataset['Kvol']],\\\n",
    "                        [dataset['Kgeo'],dataset['Kgeo'],dataset['Kgeo']]]).squeeze()\n",
    "\n",
    "\n",
    "    ncdata['%s'%m]['obs mask'] = mask\n",
    "    ncdata['%s'%m]['kernels'] = kernels\n",
    "    ncdata['%s'%m]['refl']    = refl\n",
    "    ncdata['%s'%m]['obs weight'] = weight\n",
    "    ncdata['%s'%m]['days'] = np.array([(i-d0).days for i in ncdata[m]['date']])\n",
    "\n",
    "    for i in xrange(len(bands)):\n",
    "        mm = ncdata[m]['mask_nosnow']\n",
    "        x = ncdata[m]['date'][mm]\n",
    "        y = ncdata[m]['BB_%s'%bands[i]][mm]\n",
    "        plt.plot(x,y,'+',label=bands[i])\n",
    "    plt.ylim(0,.7)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('reflectance')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('%s no snow'%m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the observation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define normalised inverse covariance (weighting) matrices $W_o$, associated with observational constraints, that are diagonal, and where each is normalised by its mean (scalar) value $w_o$ (so, if there were no difference in weighting, $W_o$ etc. would be the identity matrix $I$) and the scalar weight $w_o$ etc. is the *magnitude* of the constraint.\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "    J_o = \\frac{1}{2} w_o (y - K x)^T W_o (y - K x)\n",
    "$$\n",
    "\n",
    "Differentiation wrt $x$:\n",
    "\n",
    "$$\n",
    "    J'_o =  - w_o K^T W_o (y - K x) \n",
    "$$\n",
    "\n",
    "and again:\n",
    "\n",
    "$$\n",
    "    J''_o =  - w_o K^T W_o K \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "setting the sum of derivatives to zero:\n",
    "\n",
    "$$\n",
    "    J' = 0 = - w_o K^T W_o (y - K x) \n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "     \\left( w_o K^T W_o K  \\right) x =  \\left( w_o K^T W_o y \\right)\n",
    "$$\n",
    "\n",
    "If we wish to map parameters in $n_{bands}$ for $n_{kernels}$ for $n_{days}$ locations, then the $x$ vector shape can be given as $(n_{kernels},n_{bands},n_{days}$).\n",
    "\n",
    "In the above equations, we require $x$ to be vectorised: $vect(x)$, which has s hape  $(n_{bands} \\times n_{kernels} \\times n_{days}$).\n",
    "\n",
    "so for index $(k,b,d)$ we have position $k \\times (  n_{bands} \\times n_{days} ) + b \\times n_{days} + d$\n",
    "\n",
    "The observations $y$ can be given shape $(n_{bands},n_{obs})$ but again, this is used in vectorised form $vect(y)$ which has shape $(n_{bands} \\times n_{obs})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighting matrix $W_o$ is $(n_{bands} \\times n_{obs},n_{bands} \\times n_{obs})$ but is sparse as the uncertainty is only correlated across wavebands, so is stroed in blocks.\n",
    "\n",
    "The kernel matrix $K$ consists of sub-blocks of $(n_{bands} \\times n_{kernels},n_{bands})$ so $(9,3)$ here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how to stack the kernel blocks\n",
    "\n",
    "nbands = len(bands)\n",
    "nk = 3\n",
    "alldoys = np.arange(ndays)\n",
    "\n",
    "m = 'bbdr.meris'\n",
    "tmp = scipy.sparse.lil_matrix((nk*nbands,nbands))\n",
    "mask = ncdata[m]['obs mask']\n",
    "n = mask.shape[0]\n",
    "kk = (ncdata[m]['kernels'].reshape(nk*nbands,n))[:,mask][:,0]\n",
    "thisk = kk.reshape(nk,nbands).T\n",
    "for p in xrange(nbands):\n",
    "    tmp[p*nk:(p+1)*nk,p] = np.atleast_2d(thisk[p]).T\n",
    "print tmp.todense().shape\n",
    "print tmp.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = {}\n",
    "A = {}\n",
    "sdoys = {}\n",
    "\n",
    "# full ones\n",
    "bp = {}\n",
    "Ap = {}\n",
    "sdoysp = {}\n",
    "\n",
    "for i,m in enumerate(['bbdr.meris','bbdr.vgt','mod09','myd09']):\n",
    "#for i,m in enumerate(['mod09']):\n",
    "    print m\n",
    "    mask = ncdata['%s'%m]['obs mask']\n",
    "    n = mask.shape[0]\n",
    "    nobs = mask.sum()\n",
    "    doys = ncdata['%s'%m]['days']\n",
    "    \n",
    "    # kernels are shaped kernels[k][band][day]\n",
    "    kernels = ncdata['%s'%m]['kernels']\n",
    "    \n",
    "    # refl are shaped refl[band][day]\n",
    "    refl = np.array([ncdata['%s'%m]['refl']]).squeeze()\n",
    "    refl[np.isnan(refl)] = 0.\n",
    "    \n",
    "    # weight are shaped weight[k][band][day]\n",
    "    if ncdata['%s'%m]['obs weight'].ndim == 3:\n",
    "        weight = ncdata['%s'%m]['obs weight']\n",
    "    else:\n",
    "        weight = np.array([ncdata['%s'%m]['obs weight'].flatten()]*n).T.reshape(kernels.shape)\n",
    "    kernels = kernels[:,:,mask]\n",
    "    refl    = refl[:,mask]\n",
    "    weight  = weight[:,:,mask]\n",
    "    doys    = doys[mask]\n",
    "    print kernels.shape,refl.shape,weight.shape\n",
    "    # in essence its easiest to loop over all observations\n",
    "    # since they are independent\n",
    "    AA = []\n",
    "    bb = []\n",
    "    dd = []\n",
    "    \n",
    "    # full size sparse arrays\n",
    "    AAp = scipy.sparse.lil_matrix((nk*nbands*ndays,nk*nbands*ndays))\n",
    "    bbp = scipy.sparse.lil_matrix((nk*nbands*ndays,1))\n",
    "    ddp = np.arange(ndays)\n",
    "    \n",
    "    for p in xrange(nobs):\n",
    "        # pull out the individual pixels\n",
    "        \n",
    "        # sort the (9,3) K matrix term\n",
    "        # K (9,3)\n",
    "        tmp = scipy.sparse.lil_matrix((nk*nbands,nbands))\n",
    "        n = mask.shape[0]\n",
    "        kk = (ncdata[m]['kernels'].reshape(nk*nbands,n))[:,mask][:,p]\n",
    "        thisk = kk.reshape(nk,nbands).T\n",
    "        for q in xrange(nbands):\n",
    "            tmp[q*nk:(q+1)*nk,q] = np.atleast_2d(thisk[q]).T\n",
    "        # tmp is the sub-kernel matrix\n",
    "        # This part is checked and is correct\n",
    "        # it operates as in code example above\n",
    "            \n",
    "        # pull out the weight and reflectance for pixel p\n",
    "        # and find the day ID for this sample\n",
    "        refl_    = refl[:,p]\n",
    "        weight_  = weight[:,:,p]\n",
    "        weight_ = np.eye(nbands)\n",
    "        doy      = doys[p]\n",
    "        #import pdb;pdb.set_trace()\n",
    "        # weight is e.g.:\n",
    "        #\n",
    "        # array([[ 102.86963654,   13.86234665,  -35.25061035],\n",
    "        # [  13.86234665,   77.44153595,  -48.78294373],\n",
    "        # [ -35.25061035,  -48.78294373,  124.05032349]], dtype=float32)\n",
    "        #\n",
    "        # which is the observation uncertainty matrix\n",
    "        # we notice there are strong between band\n",
    "        # correlations in uncertainty very often\n",
    "        \n",
    "        # calculate the relevant part of the A matrix\n",
    "        # for this observation\n",
    "        # This will be a (9,9) matrix\n",
    "        # with all positive elements on\n",
    "        # the leading diagonal\n",
    "        # eg\n",
    "        # array([ 102.86963654,    0.61776894,  147.35500157,   77.44153595,\n",
    "        #  0.85568291,  113.19379327,  124.05032349,    1.02452569,\n",
    "        # 180.67130031])\n",
    "        #\n",
    "        # Note that the weight terms appear in here\n",
    "        # because the first kernel is 1\n",
    "        # so A_ is structured \n",
    "        # [b0k0,b0k1,b0k2,  b1k0,b1k1,b1k2,  b2k0,b2k1,b2k2]\n",
    "        # i.e. index = band * nk + k\n",
    "        # A_ is the individual sample A matrix\n",
    "        # and is (9,9)\n",
    "        A_ = tmp * np.matrix(weight_) * tmp.T\n",
    "        # b_ is a vector of size (9,)\n",
    "        # e.g. \n",
    "        # matrix([[  1.23429494],[ -0.09565075],[ -1.47726289],\n",
    "        # [ 13.3686551 ],[ -1.40526157],[-16.16263059],\n",
    "        # [  4.72319433],[ -0.42923813],[ -5.70008653]])\n",
    "        \n",
    "        # array([  1.23429494,  -0.09565075,  -1.47726289,  13.3686551 ,\n",
    "        # -1.40526157, -16.16263059,   4.72319433,  -0.42923813,  -5.70008653])\n",
    "        #\n",
    "        # This is built from e.g.:\n",
    "        #\n",
    "        # weight is e.g.:\n",
    "        # array([[ 102.86963654,   13.86234665,  -35.25061035],\n",
    "        # [  13.86234665,   77.44153595,  -48.78294373],\n",
    "        # [ -35.25061035,  -48.78294373,  124.05032349]], dtype=float32)\n",
    "        #\n",
    "        # eg refl =\n",
    "        # array([ 0.02774778,  0.26135752,  0.14873891], dtype=float32)\n",
    "        #\n",
    "        # weight_ * refl_\n",
    "        # matrix([[  1.23429489],[ 13.36865425],[  4.72319412]], dtype=float32)\n",
    "        #\n",
    "        # which is simply the weighted reflectance, e.g.\n",
    "        # 1.2342952249224695 = \n",
    "        # 0.02774778 * 102.86963654 + 0.26135752 * 13.86234665 + 0.14873891 *-35.25061035\n",
    "        # Note that the weighted reflectance terms\n",
    "        # directly appear in b_ every 3 items because k0 is 1.0\n",
    "        # \n",
    "        b_ = np.array(tmp * np.matrix(weight_) * np.matrix(refl_).T).flatten() \n",
    "        # [b0 k0, b0 k1, b0 k2, b1 k0, b1 k1 , ...]\n",
    "        \n",
    "        # append the individual matrices onto AA,bb,dd\n",
    "        AA.append(A_)\n",
    "        bb.append(b_)\n",
    "        dd.append(doy)\n",
    "        # load in the big one\n",
    "        # full padding  ... add terms to block in doy slot  \n",
    "        # \n",
    "        # The full matrix of A is (nbands*nk*nday, nbands*nk*nday)\n",
    "        # and b is (nbands*nk*nday,1)\n",
    "        #\n",
    "        # The indexing is:\n",
    "        # index = (d * nbands * nk) + (band*nk) + k\n",
    "        # so\n",
    "        for band in xrange(nbands):\n",
    "            for k in xrange(nk):\n",
    "                index = (doy * nbands * nk) + (band*nk) + k\n",
    "                bbp[index,0] += b_[(band*nk) + k]\n",
    "                for band2 in xrange(nbands):\n",
    "                    for k2 in xrange(nk):\n",
    "                        index2 = (doy * nbands * nk) + (band2*nk) + k2\n",
    "                        AAp[index,index2] += A_[(band*nk) + k,(band2*nk) + k2]\n",
    "        # This is the slow way to load the matrix, but we can be sure of its operation\n",
    "        # should implement a faster multi-element load\n",
    "    sdoysp[m] = ddp\n",
    "    Ap[m] = AAp\n",
    "    bp[m] = bbp\n",
    "    \n",
    "    # save the individual matrices in \n",
    "    # a dictionary\n",
    "    sdoys[m] = np.array(dd)\n",
    "    A[m] = np.array(AA)\n",
    "    b[m] = np.array(bb)   \n",
    "    \n",
    "\n",
    "# store results\n",
    "for k in A.keys():\n",
    "    print 'storing ...',k,\n",
    "    Ab = {'A':A[k],'b':b[k],'doys':sdoys[k]}\n",
    "    save_obj(Ab,'Ab_store_obs_%s'%k)\n",
    "    Ab = {'A':Ap[k],'b':bp[k],'doys':sdoysp[k]}\n",
    "    save_obj(Ab,'Ab_store_%s'%k)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(weight_)\n",
    "k = 'mod09'\n",
    "Ab = {'A':A[k],'b':b[k],'doys':sdoys[k]}\n",
    "Ab['A'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# form a D matrix -- should replace by sparse\n",
    "I = np.eye(ndays)\n",
    "D = np.matrix(I - np.roll(I,-1))\n",
    "D2 = D * D.T\n",
    "\n",
    "# form a D matrix -- should replace by sparse\n",
    "D = np.matrix(I - np.roll(I,-365))\n",
    "D2365 = D * D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D2 = scipy.sparse.lil_matrix(D2)\n",
    "D2365 = scipy.sparse.lil_matrix(D2365)\n",
    "print D2.todense()\n",
    "print D2365.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a big A matrix\n",
    "AD = scipy.sparse.lil_matrix(Ap[k].shape)\n",
    "bD = scipy.sparse.lil_matrix((Ap[k].shape[0],1))\n",
    "\n",
    "# make a big A matrix\n",
    "AD365 = scipy.sparse.lil_matrix(Ap[k].shape)\n",
    "bD365 = scipy.sparse.lil_matrix((Ap[k].shape[0],1))\n",
    "print AD.shape,bD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = nbands * nk\n",
    "for i in xrange(steps):\n",
    "    AD[i::steps,i::steps] = D2\n",
    "    AD365[i::steps,i::steps] = D2365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 'D1'\n",
    "Ab = {'A':AD,'b':bD,'doys':np.arange(ndays)}\n",
    "save_obj(Ab,'Ab_store_%s'%k)\n",
    "k = 'D365'\n",
    "Ab = {'A':AD365,'b':bD365,'doys':np.arange(ndays)}\n",
    "save_obj(Ab,'Ab_store_%s'%k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## preparing the prior matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "\n",
    "$$\n",
    "    J_p = \\frac{1}{2} w_p (x_p - x)^T W_p (x_p - x)\n",
    "$$\n",
    "\n",
    "Differentiation wrt $x$:\n",
    "\n",
    "$$\n",
    "    J'_p = - w_p W_p (x_p - x)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "\n",
    "$$\n",
    "    J''_p = w_p W_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior data are only sampled every 8 days.\n",
    "\n",
    "$x_p$ is the prior mean which can be given the shape $(n_{bands},46,n_{kernels})$\n",
    "\n",
    "The weighting matrix $W_o$ is $(n_{bands} \\times n_{kernels} \\times n_{days},n_{bands} \\times n_{kernels}\\times n_{days})$ but is sparse, and diagonal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pps = ['prior.v2.snow' ,'prior.v2.nosnow']\n",
    "\n",
    "for pp in pps:\n",
    "\n",
    "    prior = ncdata[pp]\n",
    "\n",
    "    # mean\n",
    "    mean = []\n",
    "    for b in bands:\n",
    "        m = np.array(prior['Mean_%s'%b]).squeeze().reshape(nk,46)\n",
    "        mean.append(m)\n",
    "    mean = np.array(mean)\n",
    "    print mean.shape\n",
    "\n",
    "    # var -> weight\n",
    "    kk = ['f%d'%i for i in xrange(nk)]\n",
    "    var = [[]]*nbands\n",
    "    for band in xrange(nbands):\n",
    "        var[band] = []\n",
    "        for p,f0 in enumerate(kk):\n",
    "            cc = np.array(prior['Cov_%s_%s_%s_%s'%(bands[band],f0,bands[band],f0)]).squeeze()\n",
    "            var[band].append(cc)  \n",
    "    var = np.array(var)\n",
    "    weight = 1./var\n",
    "    weight = weight/scale\n",
    "    print weight.shape\n",
    "    # these are formed \n",
    "    xp = np.zeros((nbands*nk*ndays))\n",
    "    Wp = np.zeros((nbands*nk*ndays))\n",
    "    \n",
    "    for d in xrange(ndays):\n",
    "        thisd = d0 + timedelta(d)\n",
    "        thisdoy = ((thisd - date(thisd.year,1,1)).days)/8\n",
    "        for k in xrange(nk): \n",
    "            xp[d*nbands*nk+k*nbands:d*nbands*nk+(k+1)*nbands] = mean[:,k,thisdoy]\n",
    "            Wp[d*nbands*nk+k*nbands:d*nbands*nk+(k+1)*nbands] = weight[:,k,thisdoy]\n",
    "    Ap = scipy.sparse.diags(Wp,0)\n",
    "    bp = Ap * scipy.sparse.lil_matrix(xp).T\n",
    "    Ab = {'A':Ap,'b':bp}\n",
    "    save_obj(Ab,'Ab_store_%s'%pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualise the mean and sd\n",
    "colour = ['r','g','b']\n",
    "\n",
    "for band in xrange(nbands):\n",
    "    for k in xrange(nk):\n",
    "        xx = xp[k*nbands+band::nbands*nk]\n",
    "        wx = Wp[k*nbands+band::nbands*nk]\n",
    "\n",
    "        # make an x array for plotting\n",
    "        x = np.array([np.array([[timedelta(i)+d0 \\\n",
    "                    for i in np.arange(ndays)]]).T]).T.squeeze()\n",
    "\n",
    "        # yerr for this band for the 3 kernels\n",
    "        yerr = np.sqrt(1./wx)/np.sqrt(scale)\n",
    "\n",
    "        plt.figure(figsize=(15,2))\n",
    "        plt.errorbar(x, xx, c='%s'%colour[k], yerr=yerr)\n",
    "        plt.plot(x,xx,'k+',label=kk[k])\n",
    "        plt.title('band %s kernel %s'%(bands[band],kk[k]))\n",
    "        plt.xlabel('doy')\n",
    "        plt.ylabel('kernel mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
