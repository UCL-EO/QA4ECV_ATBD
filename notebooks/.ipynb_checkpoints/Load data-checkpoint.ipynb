{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:  P. Lewis\n",
    "\n",
    "Date:    Thu 25 Feb 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section demonstrates the preparation of datasets for BRDF/albedo processing.\n",
    "\n",
    "An example is used where we have *broadband* observation datasets from MERIS, SPOT VGT `['bbdr.meris', 'bbdr.vgt']` and MODIS (Terra and Aqua) `['mod09', 'myd09']`.\n",
    "\n",
    "For testing other constraints, we also have different versions of a climatology (the 'prior') `['prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow']`.\n",
    "\n",
    "We also develop the arrays for differential constraints.\n",
    "\n",
    "For comparison, we also have the results from the GlobAlbedo processing chain `['ga.brdf.nosnow', 'ga.brdf.snow', 'ga.brdf.merge']`. [NOT YET DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load required libraries: you may need to install netCDF4\n",
    "from defaults import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datakeys = np.array(['bbdr.meris', 'bbdr.vgt', 'ga.brdf.merge',\\\n",
    "       'ga.brdf.nosnow', 'ga.brdf.snow', 'mod09', 'myd09',\\\n",
    "       'prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow'])\n",
    "# load the datasets into a dictionary in ncdata\n",
    "ncdata = {}\n",
    "for k in datakeys:\n",
    "    print k,\n",
    "    ncdata[k] = load_obj('obj/'+ k + '_s2.0_' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next consider what time period we want to do mapping for.\n",
    "\n",
    "Here, we start from the first date in the `bbdr.vgt` dataset and end on the last date of `mod09`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d0,d1 = ncdata['bbdr.vgt']['date'][0],ncdata['mod09']['date'][-1]\n",
    "print 'from',d0,'to',d1,'inclusive',\n",
    "ndays = (d1-d0).days + 1\n",
    "print 'which gives',ndays,'days'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the wavebands of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bands = np.array(['VIS','NIR','SW'])\n",
    "nbands = bands.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pull out the parts of the dataset that we want access to, and structure them in convenient forms.\n",
    "\n",
    "For `meris` and `vgt`, this is:\n",
    "\n",
    "    reflectance:\n",
    "        BB\n",
    "        \n",
    "    BRDF kernels:\n",
    "        Isotropic \n",
    "        Kvol_BRDF\n",
    "        Kgeo_BRDF\n",
    "        \n",
    "    Covariance matrix terms:\n",
    "        sig_BB\n",
    "        \n",
    "All of these terms are spectral (i.e. defined for each waveband) (so, `BB_VIS` etc., `Kvol_BRDF_VIS` etc., `sig_BB_VIS_NIR` etc.).\n",
    "\n",
    "Note that Isotropic is all ones (for valid samples), so this is provided during this reading, rather than loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pixel row col in dataset\n",
    "r,c = 0,0\n",
    "\n",
    "ncdata2 = {}\n",
    "\n",
    "for m in ['mod09', 'meris','vgt',  'myd09']:\n",
    "    plt.figure(figsize=(15,3))\n",
    "    \n",
    "    # ID the datazet\n",
    "    try:\n",
    "        mm = 'bbdr.%s'%m\n",
    "        dataset = ncdata[mm]\n",
    "        ncdata2[mm] = dataset2 = {}\n",
    "        # these are 3D datasets\n",
    "        sl = (slice(None),r,c)\n",
    "        sVis = '_BRDF_VIS'\n",
    "        sNir = '_BRDF_NIR'\n",
    "        sSw  = '_BRDF_SW'\n",
    "        datatype = 'A'\n",
    "        \n",
    "    except:\n",
    "        # these may be 1 D but need to fix\n",
    "        mm = m\n",
    "        dataset = ncdata[mm]\n",
    "        ncdata2[mm] = dataset2 = {}\n",
    "        sl = slice(None)\n",
    "        sVis = sNir = sSw = ''\n",
    "        datatype = 'B'\n",
    "        \n",
    "    # pull reflectance data\n",
    "    refl = np.array([np.array(dataset['BB_VIS'])[sl],\n",
    "                     np.array(dataset['BB_NIR'])[sl],\n",
    "                     np.array(dataset['BB_SW'])[sl]])\n",
    "    # identify dodgy values from refl\n",
    "    # these data are shaped (nbands, nsamples)\n",
    "    # If any of the nbands is False, we want to ignore all bands\n",
    "    # so \n",
    "    mask = ((refl>0)*(refl<1)).prod(axis=0).astype(bool)\n",
    "    try:\n",
    "        # assuming dataset['mask'] is True for good data\n",
    "        mask = np.logical_and(np.array(dataset['mask'])[sl],mask)\n",
    "    except:\n",
    "        pass\n",
    "    # easiest to reload now ...\n",
    "    refl = np.array([np.array(dataset['BB_VIS'])[sl][mask],\n",
    "                     np.array(dataset['BB_NIR'])[sl][mask],\n",
    "                     np.array(dataset['BB_SW'])[sl][mask]])\n",
    "\n",
    "    # isotropic\n",
    "    Isotropic = np.ones_like(dataset['Kvol%s'%sVis])\n",
    "    # kernels\n",
    "    kernels = np.array([[Isotropic[sl][mask],\\\n",
    "                         Isotropic[sl][mask],\\\n",
    "                         Isotropic[sl][mask]],\\\n",
    "                        [np.array(dataset['Kvol%s'%sVis])[sl][mask],\\\n",
    "                         np.array(dataset['Kvol%s'%sNir])[sl][mask],\\\n",
    "                         np.array(dataset['Kvol%s'%sSw])[sl][mask]],\\\n",
    "                        [np.array(dataset['Kgeo%s'%sVis])[sl][mask],\\\n",
    "                         np.array(dataset['Kgeo%s'%sNir])[sl][mask],\\\n",
    "                         np.array(dataset['Kgeo%s'%sSw])[sl][mask]]\\\n",
    "                       ])\n",
    "    \n",
    "    # uncertainty\n",
    "    if datatype == 'A':\n",
    "        var     = np.array([[np.array(dataset['sig_BB_VIS_VIS'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_VIS_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_VIS_SW'])[sl][mask]],\\\n",
    "                        [np.array(dataset['sig_BB_VIS_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_NIR'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_SW'])[sl][mask]],\\\n",
    "                        [np.array(dataset['sig_BB_VIS_SW'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_NIR_SW'])[sl][mask],\\\n",
    "                         np.array(dataset['sig_BB_SW_SW'])[sl][mask]]\\\n",
    "                       ])    \n",
    "\n",
    "        weight = np.zeros_like(var)\n",
    "        for i in xrange(refl.shape[-1]):\n",
    "            try:\n",
    "                weight[...,i] = np.matrix(var[...,i]).I\n",
    "            except:\n",
    "                pass\n",
    "        del var\n",
    "    elif datatype == 'B':\n",
    "        w1 = [[dataset['weight_BB_VIS_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_NIR_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_VIS']]*len(mask)]\n",
    "        w2 = [[dataset['weight_BB_NIR_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_NIR_NIR']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_NIR']]*len(mask)]\n",
    "        w3 = [[dataset['weight_BB_SW_VIS']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_NIR']]*len(mask),\\\n",
    "                            [dataset['weight_BB_SW_SW']]*len(mask)]\n",
    "        weight = np.array([w1,w2,w3])  \n",
    "        weight = weight[...,mask]\n",
    "\n",
    "    dates = dataset['date'][mask]        \n",
    "    \n",
    "    # store in dataset2\n",
    "    dataset2['refl'] = refl.copy()\n",
    "    dataset2['kernels'] = kernels.copy()\n",
    "    dataset2['weight'] = weight.copy()\n",
    "    dataset2['date'] = dates.copy()\n",
    "    dataset2['year'] = np.array(dataset['yeardoy'])[:,0]\n",
    "    dataset2['doy'] = np.array(dataset['yeardoy'])[:,1]\n",
    "    dataset2['idoy'] = np.array([k.days for k in (dates - d0)])\n",
    "    \n",
    "    \n",
    "    # form A and b matrices\n",
    "    nk = dataset2['kernels'].shape[0]\n",
    "    bigshape = tuple(np.array([ndays,ndays]) * nk * nbands)\n",
    "    AD = scipy.sparse.lil_matrix(bigshape)\n",
    "    bD = scipy.sparse.lil_matrix((bigshape[0],1))\n",
    "    steps = nbands * nk\n",
    "    nsamp = dataset2['kernels'].shape[-1]\n",
    "    \n",
    "    # load into A and b matrices\n",
    "    #Â loop over samples\n",
    "    for i in xrange(nsamp):\n",
    "        # the information for this sample\n",
    "        thisR = np.matrix(refl[...,i]).T\n",
    "        thisK = np.matrix(kernels[...,i]).T\n",
    "        thisW = np.matrix(weight[...,i])\n",
    "        thisdoy = dataset2['idoy'][i]\n",
    "        k=np.matrix(np.zeros((nbands,nbands*nk)))\n",
    "        # load k\n",
    "        for i in xrange(nbands): k[i,i*nk:(i+1)*nk] = thisK[i]\n",
    "        thisKR = k.T*thisW*thisR\n",
    "        thisKK = k.T*thisW*k\n",
    "        sli = slice(i*steps,(i+1)*steps)\n",
    "        \n",
    "        # add ie accumulate in case of multiple samples per day\n",
    "        AD[sli,sli] += thisKK\n",
    "        bD[sli,0] += thisKR\n",
    "    Ab = {'A':AD,'b':bD,'doys':np.arange(ndays),'d0':d0}\n",
    "    save_obj(Ab,'obj/' + mm+'_Ab_')\n",
    "\n",
    "    for i in xrange(nbands):\n",
    "        plt.plot(dates,refl[i],'+')\n",
    "    plt.ylim(0,.7)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('reflectance')\n",
    "    #plt.legend(loc='best')\n",
    "    plt.title('%s no snow'%m)\n",
    "    \n",
    "# save as s3.0\n",
    "for k in datakeys:\n",
    "    try:\n",
    "        save_obj(ncdata2[k],'obj/' + k+'_s3.0_')\n",
    "        print k,\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we form and store the derivative matrix we need for naive implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# form a D matrix -- should replace by sparse\n",
    "I = np.eye(ndays)\n",
    "D = np.matrix(I - np.roll(I,-1))\n",
    "D1 = D * D.T\n",
    "\n",
    "# form a D matrix -- should replace by sparse\n",
    "D = np.matrix(I - np.roll(I,-365))\n",
    "D1365 = D * D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D1 = scipy.sparse.lil_matrix(D1)\n",
    "D1365 = scipy.sparse.lil_matrix(D1365)\n",
    "print D1.todense()\n",
    "print D1365.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nk = dataset2['kernels'].shape[0]\n",
    "bigshape = tuple(np.array(D1.shape) * nk * nbands)\n",
    "print bigshape\n",
    "AD = scipy.sparse.lil_matrix(bigshape)\n",
    "bD = scipy.sparse.lil_matrix((bigshape[0],1))\n",
    "\n",
    "# make a big A matrix\n",
    "AD365 = scipy.sparse.lil_matrix(bigshape)\n",
    "bD365 = scipy.sparse.lil_matrix((bigshape[0],1))\n",
    "print AD.shape,bD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = nbands * nk\n",
    "for i in xrange(steps):\n",
    "    AD[i::steps,i::steps] = D1\n",
    "    AD365[i::steps,i::steps] = D1365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 'D1'\n",
    "Ab = {'A':AD,'b':bD,'doys':np.arange(ndays),'d0':d0}\n",
    "save_obj(Ab,'obj/' + k+'_Ab_')\n",
    "print k,\n",
    "k = 'D365'\n",
    "Ab = {'A':AD,'b':bD,'doys':np.arange(ndays),'d0':d0}\n",
    "save_obj(Ab,'obj/' + k+'_Ab_')\n",
    "print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show how this is arranged:\n",
    "\n",
    "for j in xrange(20): \n",
    "    for i in xrange(20): \n",
    "        print AD[j,i],\n",
    "    print\n",
    "    \n",
    "# so, it is made up of 9 x 9 blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## preparing the prior matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "\n",
    "$$\n",
    "    J_p = \\frac{1}{2} w_p (x_p - x)^T W_p (x_p - x)\n",
    "$$\n",
    "\n",
    "Differentiation wrt $x$:\n",
    "\n",
    "$$\n",
    "    J'_p = - w_p W_p (x_p - x)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "\n",
    "$$\n",
    "    J''_p = w_p W_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior data are only sampled every 8 days.\n",
    "\n",
    "$x_p$ is the prior mean which can be given the shape $(n_{bands},46,n_{kernels})$\n",
    "\n",
    "The weighting matrix $W_o$ is $(n_{bands} \\times n_{kernels} \\times n_{days},n_{bands} \\times n_{kernels}\\times n_{days})$ but is sparse, and diagonal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pps = ['prior.v2.snow' ,'prior.v2.nosnow']\n",
    "\n",
    "for pp in pps:\n",
    "\n",
    "    prior = ncdata[pp]\n",
    "\n",
    "    # mean\n",
    "    mean = []\n",
    "    for b in bands:\n",
    "        m = np.array(prior['Mean_%s'%b]).squeeze().reshape(nk,46)\n",
    "        mean.append(m)\n",
    "    mean = np.array(mean)\n",
    "    print mean.shape\n",
    "\n",
    "    # var -> weight\n",
    "    kk = ['f%d'%i for i in xrange(nk)]\n",
    "    var = [[]]*nbands\n",
    "    for band in xrange(nbands):\n",
    "        var[band] = []\n",
    "        for p,f0 in enumerate(kk):\n",
    "            cc = np.array(prior['Cov_%s_%s_%s_%s'%(bands[band],f0,bands[band],f0)]).squeeze()\n",
    "            var[band].append(cc)  \n",
    "    var = np.array(var)\n",
    "    weight = 1./var\n",
    "    weight = weight/scale\n",
    "    print weight.shape\n",
    "    # these are formed \n",
    "    xp = np.zeros((nbands*nk*ndays))\n",
    "    Wp = np.zeros((nbands*nk*ndays))\n",
    "    \n",
    "    for d in xrange(ndays):\n",
    "        thisd = d0 + timedelta(d)\n",
    "        thisdoy = ((thisd - date(thisd.year,1,1)).days)/8\n",
    "        for k in xrange(nk): \n",
    "            xp[d*nbands*nk+k*nbands:d*nbands*nk+(k+1)*nbands] = mean[:,k,thisdoy]\n",
    "            Wp[d*nbands*nk+k*nbands:d*nbands*nk+(k+1)*nbands] = weight[:,k,thisdoy]\n",
    "    Ap = scipy.sparse.diags(Wp,0)\n",
    "    bp = Ap * scipy.sparse.lil_matrix(xp).T\n",
    "    Ab = {'A':Ap,'b':bp,'doys':np.arange(ndays),'d0':d0}\n",
    "    save_obj(Ab,'obj/' + pp + '_Ab_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualise the mean and sd\n",
    "colour = ['r','g','b']\n",
    "\n",
    "for band in xrange(nbands):\n",
    "    for k in xrange(nk):\n",
    "        xx = xp[k*nbands+band::nbands*nk]\n",
    "        wx = Wp[k*nbands+band::nbands*nk]\n",
    "\n",
    "        # make an x array for plotting\n",
    "        x = np.array([np.array([[timedelta(i)+d0 \\\n",
    "                    for i in np.arange(ndays)]]).T]).T.squeeze()\n",
    "\n",
    "        # yerr for this band for the 3 kernels\n",
    "        yerr = np.sqrt(1./wx)/np.sqrt(scale)\n",
    "\n",
    "        plt.figure(figsize=(15,2))\n",
    "        plt.errorbar(x, xx, c='%s'%colour[k], yerr=yerr)\n",
    "        plt.plot(x,xx,'k+',label=kk[k])\n",
    "        plt.title('band %s kernel %s'%(bands[band],kk[k]))\n",
    "        plt.xlabel('doy')\n",
    "        plt.ylabel('kernel mean')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
