{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobAlbedo and associated algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P. Lewis and M. van Leeuwen, UCL/NCEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first notebook deals with downloading the data from the database and constructing suitable data structures.\n",
    "\n",
    "The various forms of (netcdf) inputs are read and the data organised as a set of arrays in set of dictionaries.\n",
    "\n",
    "These dictionaries are then 'pickled' (saved to disk) for direct use in further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory /Users/plewis/QA4ECV_ATBD/data\n"
     ]
    }
   ],
   "source": [
    "from defaults import *\n",
    "%matplotlib inline\n",
    "db = 'http://gws-access.cems.rl.ac.uk/public/globalbedo/.stackXY2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to http://gws-access.cems.rl.ac.uk/public/globalbedo/.stackXY2/\n",
      "got urls\n",
      "prior.v1.nosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . prior.v1.snow2/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ga.brdf.snow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbdr.vgt/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . prior.v2.snownosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbdr.flags/\n",
      "prior.v2.snow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ga.brdf.merge/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbdr.meris/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . mod09/\n",
      ". . . . . . . . . . . . . . . . . . . . . . ga.brdf.nosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . prior.v2.nosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . myd09/\n",
      ". . . . . . . . . . . . . . . . . . . . . . prior.v1.snow1/\n",
      ". . . . . . . . . . . . . . . . . . . . ['bbdr.flags' 'bbdr.meris' 'bbdr.vgt' 'ga.brdf.merge' 'ga.brdf.nosnow'\n",
      " 'ga.brdf.snow' 'mod09' 'myd09' 'prior.v1.nosnow' 'prior.v1.snow1'\n",
      " 'prior.v1.snow2' 'prior.v2.nosnow' 'prior.v2.snow' 'prior.v2.snownosnow']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Contact the server for a listing and \n",
    "if doit is True download the files and pack into\n",
    "the dictionary ncfiles. \n",
    "\n",
    "Actually, all we really need (to access pre-stored pickle files)\n",
    "is to set the variable  `datakeys`\n",
    "'''\n",
    "\n",
    "doit = True\n",
    "# set True if you want to download as well\n",
    "ncfiles = obtain_data(db,doit=doit)\n",
    "datakeys = ncfiles.keys()\n",
    "if None:\n",
    "    # this is most of them\n",
    "    \n",
    "#        'prior.v1.nosnow', 'prior.v1.snow1', 'prior.v1.snow2',\\\n",
    "\n",
    "print np.sort(datakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbdr.flags' 'bbdr.meris' 'bbdr.vgt' 'ga.brdf.merge' 'ga.brdf.nosnow'\n",
      " 'ga.brdf.snow' 'mod09' 'myd09' 'prior.v2.nosnow' 'prior.v2.snow'\n",
      " 'prior.v2.snownosnow']\n"
     ]
    }
   ],
   "source": [
    "# actually, we only want these particular datasets\n",
    "datakeys = np.array(['bbdr.flags', 'bbdr.meris', 'bbdr.vgt', 'ga.brdf.merge',\\\n",
    "       'ga.brdf.nosnow', 'ga.brdf.snow', 'mod09', 'myd09',\\\n",
    "       'prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow'])\n",
    "\n",
    "print np.sort(datakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbdr.flags\n",
      "bbdr.meris\n",
      "bbdr.vgt\n",
      "ga.brdf.merge\n",
      "TIME\n",
      "ga.brdf.merge VAR_NIR_f0_NIR_f0 ; ga.brdf.merge VAR_NIR_f0_NIR_f1 ; ga.brdf.merge VAR_NIR_f0_NIR_f2 ; ga.brdf.merge VAR_NIR_f0_SW_f0 ; ga.brdf.merge VAR_NIR_f0_SW_f1 ; ga.brdf.merge VAR_NIR_f0_SW_f2 ; ga.brdf.merge VAR_NIR_f1_NIR_f1 ; ga.brdf.merge VAR_NIR_f1_NIR_f2 ; ga.brdf.merge VAR_NIR_f1_SW_f0 ; ga.brdf.merge VAR_NIR_f1_SW_f1 ; ga.brdf.merge VAR_NIR_f1_SW_f2 ; ga.brdf.merge VAR_NIR_f2_NIR_f2 ; ga.brdf.merge VAR_NIR_f2_SW_f0 ; ga.brdf.merge VAR_NIR_f2_SW_f1 ; ga.brdf.merge VAR_NIR_f2_SW_f2 ; ga.brdf.merge VAR_SW_f0_SW_f0 ; ga.brdf.merge VAR_SW_f0_SW_f1 ; ga.brdf.merge VAR_SW_f0_SW_f2 ; ga.brdf.merge VAR_SW_f1_SW_f1 ; ga.brdf.merge VAR_SW_f1_SW_f2 ; ga.brdf.merge VAR_SW_f2_SW_f2 ; ga.brdf.merge VAR_VIS_f0_NIR_f0 ; ga.brdf.merge VAR_VIS_f0_NIR_f1 ; ga.brdf.merge VAR_VIS_f0_NIR_f2 ; ga.brdf.merge VAR_VIS_f0_SW_f0 ; ga.brdf.merge VAR_VIS_f0_SW_f1 ; ga.brdf.merge VAR_VIS_f0_SW_f2 ; ga.brdf.merge VAR_VIS_f0_VIS_f0 ; ga.brdf.merge VAR_VIS_f0_VIS_f1 ; ga.brdf.merge VAR_VIS_f0_VIS_f2 ; ga.brdf.merge VAR_VIS_f1_NIR_f0 ; ga.brdf.merge VAR_VIS_f1_NIR_f1 ; ga.brdf.merge VAR_VIS_f1_NIR_f2 ; ga.brdf.merge VAR_VIS_f1_SW_f0 ; ga.brdf.merge VAR_VIS_f1_SW_f1 ; ga.brdf.merge VAR_VIS_f1_SW_f2 ; ga.brdf.merge VAR_VIS_f1_VIS_f1 ; ga.brdf.merge VAR_VIS_f1_VIS_f2 ; ga.brdf.merge VAR_VIS_f2_NIR_f0 ; ga.brdf.merge VAR_VIS_f2_NIR_f1 ; ga.brdf.merge VAR_VIS_f2_NIR_f2 ; ga.brdf.merge VAR_VIS_f2_SW_f0 ; ga.brdf.merge VAR_VIS_f2_SW_f1 ; ga.brdf.merge VAR_VIS_f2_SW_f2 ; ga.brdf.merge VAR_VIS_f2_VIS_f2 ; ga.brdf.merge mean_NIR_f0 ; ga.brdf.merge mean_NIR_f1 ; ga.brdf.merge mean_NIR_f2 ; ga.brdf.merge mean_SW_f0 ; ga.brdf.merge mean_SW_f1 ; ga.brdf.merge mean_SW_f2 ; ga.brdf.merge mean_VIS_f0 ; ga.brdf.merge mean_VIS_f1 ; ga.brdf.merge mean_VIS_f2 ; ga.brdf.nosnow\n",
      "TIME\n",
      "ga.brdf.nosnow VAR_NIR_f0_NIR_f0 ; ga.brdf.nosnow VAR_NIR_f0_NIR_f1 ; ga.brdf.nosnow VAR_NIR_f0_NIR_f2 ; ga.brdf.nosnow VAR_NIR_f0_SW_f0 ; ga.brdf.nosnow VAR_NIR_f0_SW_f1 ; ga.brdf.nosnow VAR_NIR_f0_SW_f2 ; ga.brdf.nosnow VAR_NIR_f1_NIR_f1 ; ga.brdf.nosnow VAR_NIR_f1_NIR_f2 ; ga.brdf.nosnow VAR_NIR_f1_SW_f0 ; ga.brdf.nosnow VAR_NIR_f1_SW_f1 ; ga.brdf.nosnow VAR_NIR_f1_SW_f2 ; ga.brdf.nosnow VAR_NIR_f2_NIR_f2 ; ga.brdf.nosnow VAR_NIR_f2_SW_f0 ; ga.brdf.nosnow VAR_NIR_f2_SW_f1 ; ga.brdf.nosnow VAR_NIR_f2_SW_f2 ; ga.brdf.nosnow VAR_SW_f0_SW_f0 ; ga.brdf.nosnow VAR_SW_f0_SW_f1 ; ga.brdf.nosnow VAR_SW_f0_SW_f2 ; ga.brdf.nosnow VAR_SW_f1_SW_f1 ; ga.brdf.nosnow VAR_SW_f1_SW_f2 ; ga.brdf.nosnow VAR_SW_f2_SW_f2 ; ga.brdf.nosnow VAR_VIS_f0_NIR_f0 ; ga.brdf.nosnow VAR_VIS_f0_NIR_f1 ; ga.brdf.nosnow VAR_VIS_f0_NIR_f2 ; ga.brdf.nosnow VAR_VIS_f0_SW_f0 ; ga.brdf.nosnow VAR_VIS_f0_SW_f1 ; ga.brdf.nosnow VAR_VIS_f0_SW_f2 ; ga.brdf.nosnow VAR_VIS_f0_VIS_f0 ; ga.brdf.nosnow VAR_VIS_f0_VIS_f1 ; ga.brdf.nosnow VAR_VIS_f0_VIS_f2 ; ga.brdf.nosnow VAR_VIS_f1_NIR_f0 ; ga.brdf.nosnow VAR_VIS_f1_NIR_f1 ; ga.brdf.nosnow VAR_VIS_f1_NIR_f2 ; ga.brdf.nosnow VAR_VIS_f1_SW_f0 ; ga.brdf.nosnow VAR_VIS_f1_SW_f1 ; ga.brdf.nosnow VAR_VIS_f1_SW_f2 ; ga.brdf.nosnow VAR_VIS_f1_VIS_f1 ; ga.brdf.nosnow VAR_VIS_f1_VIS_f2 ; ga.brdf.nosnow VAR_VIS_f2_NIR_f0 ; ga.brdf.nosnow VAR_VIS_f2_NIR_f1 ; ga.brdf.nosnow VAR_VIS_f2_NIR_f2 ; ga.brdf.nosnow VAR_VIS_f2_SW_f0 ; ga.brdf.nosnow VAR_VIS_f2_SW_f1 ; ga.brdf.nosnow VAR_VIS_f2_SW_f2 ; ga.brdf.nosnow VAR_VIS_f2_VIS_f2 ; ga.brdf.nosnow mean_NIR_f0 ; ga.brdf.nosnow mean_NIR_f1 ; ga.brdf.nosnow mean_NIR_f2 ; ga.brdf.nosnow mean_SW_f0 ; ga.brdf.nosnow mean_SW_f1 ; ga.brdf.nosnow mean_SW_f2 ; ga.brdf.nosnow mean_VIS_f0 ; ga.brdf.nosnow mean_VIS_f1 ; ga.brdf.nosnow mean_VIS_f2 ; ga.brdf.snow\n",
      "TIME\n",
      "ga.brdf.snow VAR_NIR_f0_NIR_f0 ; ga.brdf.snow VAR_NIR_f0_NIR_f1 ; ga.brdf.snow VAR_NIR_f0_NIR_f2 ; ga.brdf.snow VAR_NIR_f0_SW_f0 ; ga.brdf.snow VAR_NIR_f0_SW_f1 ; ga.brdf.snow VAR_NIR_f0_SW_f2 ; ga.brdf.snow VAR_NIR_f1_NIR_f1 ; ga.brdf.snow VAR_NIR_f1_NIR_f2 ; ga.brdf.snow VAR_NIR_f1_SW_f0 ; ga.brdf.snow VAR_NIR_f1_SW_f1 ; ga.brdf.snow VAR_NIR_f1_SW_f2 ; ga.brdf.snow VAR_NIR_f2_NIR_f2 ; ga.brdf.snow VAR_NIR_f2_SW_f0 ; ga.brdf.snow VAR_NIR_f2_SW_f1 ; ga.brdf.snow VAR_NIR_f2_SW_f2 ; ga.brdf.snow VAR_SW_f0_SW_f0 ; ga.brdf.snow VAR_SW_f0_SW_f1 ; ga.brdf.snow VAR_SW_f0_SW_f2 ; ga.brdf.snow VAR_SW_f1_SW_f1 ; ga.brdf.snow VAR_SW_f1_SW_f2 ; ga.brdf.snow VAR_SW_f2_SW_f2 ; ga.brdf.snow VAR_VIS_f0_NIR_f0 ; ga.brdf.snow VAR_VIS_f0_NIR_f1 ; ga.brdf.snow VAR_VIS_f0_NIR_f2 ; ga.brdf.snow VAR_VIS_f0_SW_f0 ; ga.brdf.snow VAR_VIS_f0_SW_f1 ; ga.brdf.snow VAR_VIS_f0_SW_f2 ; ga.brdf.snow VAR_VIS_f0_VIS_f0 ; ga.brdf.snow VAR_VIS_f0_VIS_f1 ; ga.brdf.snow VAR_VIS_f0_VIS_f2 ; ga.brdf.snow VAR_VIS_f1_NIR_f0 ; ga.brdf.snow VAR_VIS_f1_NIR_f1 ; ga.brdf.snow VAR_VIS_f1_NIR_f2 ; ga.brdf.snow VAR_VIS_f1_SW_f0 ; ga.brdf.snow VAR_VIS_f1_SW_f1 ; ga.brdf.snow VAR_VIS_f1_SW_f2 ; ga.brdf.snow VAR_VIS_f1_VIS_f1 ; ga.brdf.snow VAR_VIS_f1_VIS_f2 ; ga.brdf.snow VAR_VIS_f2_NIR_f0 ; ga.brdf.snow VAR_VIS_f2_NIR_f1 ; ga.brdf.snow VAR_VIS_f2_NIR_f2 ; ga.brdf.snow VAR_VIS_f2_SW_f0 ; ga.brdf.snow VAR_VIS_f2_SW_f1 ; ga.brdf.snow VAR_VIS_f2_SW_f2 ; ga.brdf.snow VAR_VIS_f2_VIS_f2 ; ga.brdf.snow mean_NIR_f0 ; ga.brdf.snow mean_NIR_f1 ; ga.brdf.snow mean_NIR_f2 ; ga.brdf.snow mean_SW_f0 ; ga.brdf.snow mean_SW_f1 ; ga.brdf.snow mean_SW_f2 ; ga.brdf.snow mean_VIS_f0 ; ga.brdf.snow mean_VIS_f1 ; ga.brdf.snow mean_VIS_f2 ; mod09\n",
      "TIME\n",
      "mod09 MODIS_Grid_1km_2D_Data_Fields_Range ; mod09 MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth ; mod09 MODIS_Grid_1km_2D_Data_Fields_SensorZenith ; mod09 MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth ; mod09 MODIS_Grid_1km_2D_Data_Fields_SolarZenith ; mod09 MODIS_Grid_1km_2D_Data_Fields_gflags ; mod09 MODIS_Grid_1km_2D_Data_Fields_granule_pnt ; mod09 MODIS_Grid_1km_2D_Data_Fields_orbit_pnt ; mod09 MODIS_Grid_1km_2D_Data_Fields_state_1km ; mod09 MODIS_Grid_500m_2D_Data_Fields_QC_500m ; mod09 MODIS_Grid_500m_2D_Data_Fields_iobs_res ; mod09 MODIS_Grid_500m_2D_Data_Fields_obscov_500m ; mod09 MODIS_Grid_500m_2D_Data_Fields_q_scan ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b02 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b03 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b04 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b05 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b06 ; mod09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b07 ; myd09\n",
      "TIME\n",
      "myd09 MODIS_Grid_1km_2D_Data_Fields_Range ; myd09 MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth ; myd09 MODIS_Grid_1km_2D_Data_Fields_SensorZenith ; myd09 MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth ; myd09 MODIS_Grid_1km_2D_Data_Fields_SolarZenith ; myd09 MODIS_Grid_1km_2D_Data_Fields_gflags ; myd09 MODIS_Grid_1km_2D_Data_Fields_granule_pnt ; myd09 MODIS_Grid_1km_2D_Data_Fields_orbit_pnt ; myd09 MODIS_Grid_1km_2D_Data_Fields_state_1km ; myd09 MODIS_Grid_500m_2D_Data_Fields_QC_500m ; myd09 MODIS_Grid_500m_2D_Data_Fields_iobs_res ; myd09 MODIS_Grid_500m_2D_Data_Fields_obscov_500m ; myd09 MODIS_Grid_500m_2D_Data_Fields_q_scan ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b02 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b03 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b04 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b05 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b06 ; myd09 MODIS_Grid_500m_2D_Data_Fields_sur_refl_b07 ; prior.v2.nosnow\n",
      "TIME\n",
      "prior.v2.nosnow Cov_NIR_f0_NIR_f0 ; prior.v2.nosnow Cov_NIR_f0_NIR_f1 ; prior.v2.nosnow Cov_NIR_f0_NIR_f2 ; prior.v2.nosnow Cov_NIR_f0_SW_f0 ; prior.v2.nosnow Cov_NIR_f0_SW_f1 ; prior.v2.nosnow Cov_NIR_f0_SW_f2 ; prior.v2.nosnow Cov_NIR_f1_NIR_f1 ; prior.v2.nosnow Cov_NIR_f1_NIR_f2 ; prior.v2.nosnow Cov_NIR_f1_SW_f0 ; prior.v2.nosnow Cov_NIR_f1_SW_f1 ; prior.v2.nosnow Cov_NIR_f1_SW_f2 ; prior.v2.nosnow Cov_NIR_f2_NIR_f2 ; prior.v2.nosnow Cov_NIR_f2_SW_f0 ; prior.v2.nosnow Cov_NIR_f2_SW_f1 ; prior.v2.nosnow Cov_NIR_f2_SW_f2 ; prior.v2.nosnow Cov_SW_f0_SW_f0 ; prior.v2.nosnow Cov_SW_f0_SW_f1 ; prior.v2.nosnow Cov_SW_f0_SW_f2 ; prior.v2.nosnow Cov_SW_f1_SW_f1 ; prior.v2.nosnow Cov_SW_f1_SW_f2 ; prior.v2.nosnow Cov_SW_f2_SW_f2 ; prior.v2.nosnow Cov_VIS_f0_NIR_f0 ; prior.v2.nosnow Cov_VIS_f0_NIR_f1 ; prior.v2.nosnow Cov_VIS_f0_NIR_f2 ; prior.v2.nosnow Cov_VIS_f0_SW_f0 ; prior.v2.nosnow Cov_VIS_f0_SW_f1 ; prior.v2.nosnow Cov_VIS_f0_SW_f2 ; prior.v2.nosnow Cov_VIS_f0_VIS_f0 ; prior.v2.nosnow Cov_VIS_f0_VIS_f1 ; prior.v2.nosnow Cov_VIS_f0_VIS_f2 ; prior.v2.nosnow Cov_VIS_f1_NIR_f0 ; prior.v2.nosnow Cov_VIS_f1_NIR_f1 ; prior.v2.nosnow Cov_VIS_f1_NIR_f2 ; prior.v2.nosnow Cov_VIS_f1_SW_f0 ; prior.v2.nosnow Cov_VIS_f1_SW_f1 ; prior.v2.nosnow Cov_VIS_f1_SW_f2 ; prior.v2.nosnow Cov_VIS_f1_VIS_f1 ; prior.v2.nosnow Cov_VIS_f1_VIS_f2 ; prior.v2.nosnow Cov_VIS_f2_NIR_f0 ; prior.v2.nosnow Cov_VIS_f2_NIR_f1 ; prior.v2.nosnow Cov_VIS_f2_NIR_f2 ; prior.v2.nosnow Cov_VIS_f2_SW_f0 ; prior.v2.nosnow Cov_VIS_f2_SW_f1 ; prior.v2.nosnow Cov_VIS_f2_SW_f2 ; prior.v2.nosnow Cov_VIS_f2_VIS_f2 ; prior.v2.nosnow Data_Mask ; prior.v2.nosnow Mean_NIR ; prior.v2.nosnow Mean_SW ; prior.v2.nosnow Mean_VIS ; prior.v2.nosnow Snow_Fraction ; prior.v2.snow\n",
      "TIME\n",
      "prior.v2.snow Cov_NIR_f0_NIR_f0 ; prior.v2.snow Cov_NIR_f0_NIR_f1 ; prior.v2.snow Cov_NIR_f0_NIR_f2 ; prior.v2.snow Cov_NIR_f0_SW_f0 ; prior.v2.snow Cov_NIR_f0_SW_f1 ; prior.v2.snow Cov_NIR_f0_SW_f2 ; prior.v2.snow Cov_NIR_f1_NIR_f1 ; prior.v2.snow Cov_NIR_f1_NIR_f2 ; prior.v2.snow Cov_NIR_f1_SW_f0 ; prior.v2.snow Cov_NIR_f1_SW_f1 ; prior.v2.snow Cov_NIR_f1_SW_f2 ; prior.v2.snow Cov_NIR_f2_NIR_f2 ; prior.v2.snow Cov_NIR_f2_SW_f0 ; prior.v2.snow Cov_NIR_f2_SW_f1 ; prior.v2.snow Cov_NIR_f2_SW_f2 ; prior.v2.snow Cov_SW_f0_SW_f0 ; prior.v2.snow Cov_SW_f0_SW_f1 ; prior.v2.snow Cov_SW_f0_SW_f2 ; prior.v2.snow Cov_SW_f1_SW_f1 ; prior.v2.snow Cov_SW_f1_SW_f2 ; prior.v2.snow Cov_SW_f2_SW_f2 ; prior.v2.snow Cov_VIS_f0_NIR_f0 ; prior.v2.snow Cov_VIS_f0_NIR_f1 ; prior.v2.snow Cov_VIS_f0_NIR_f2 ; prior.v2.snow Cov_VIS_f0_SW_f0 ; prior.v2.snow Cov_VIS_f0_SW_f1 ; prior.v2.snow Cov_VIS_f0_SW_f2 ; prior.v2.snow Cov_VIS_f0_VIS_f0 ; prior.v2.snow Cov_VIS_f0_VIS_f1 ; prior.v2.snow Cov_VIS_f0_VIS_f2 ; prior.v2.snow Cov_VIS_f1_NIR_f0 ; prior.v2.snow Cov_VIS_f1_NIR_f1 ; prior.v2.snow Cov_VIS_f1_NIR_f2 ; prior.v2.snow Cov_VIS_f1_SW_f0 ; prior.v2.snow Cov_VIS_f1_SW_f1 ; prior.v2.snow Cov_VIS_f1_SW_f2 ; prior.v2.snow Cov_VIS_f1_VIS_f1 ; prior.v2.snow Cov_VIS_f1_VIS_f2 ; prior.v2.snow Cov_VIS_f2_NIR_f0 ; prior.v2.snow Cov_VIS_f2_NIR_f1 ; prior.v2.snow Cov_VIS_f2_NIR_f2 ; prior.v2.snow Cov_VIS_f2_SW_f0 ; prior.v2.snow Cov_VIS_f2_SW_f1 ; prior.v2.snow Cov_VIS_f2_SW_f2 ; prior.v2.snow Cov_VIS_f2_VIS_f2 ; prior.v2.snow Data_Mask ; prior.v2.snow Mean_NIR ; prior.v2.snow Mean_SW ; prior.v2.snow Mean_VIS ; prior.v2.snow Snow_Fraction ; prior.v2.snownosnow\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Form the data dictionary (in ncdata), reading and storing each of the\n",
    "datasets in datakeys.\n",
    "\n",
    "The only complexities in the code are to do with correcting some variants\n",
    "(e.g. 'MEAN__BAND________' -> 'MEAN_BAND')\n",
    "\n",
    "The default parsing splits the key on _1_:\n",
    "\n",
    "thiskey = kk.split('_1_')[0]\n",
    "\n",
    "A set of 'special' keys are defined that need to be split / interpreted differently\n",
    "These are specified in the dictionary specials, with the key name and an integer specifying\n",
    "how many terms to include.\n",
    "\n",
    "To decode the TIME field, we look at the keys for\n",
    "'Cov_NIR_f0_NIR_f0','VAR_NIR_f0_NIR_f0','BB_NIR','MODIS_Grid_1km_2D_Data_Fields_Range'\n",
    "any one of which can lead to the time field.\n",
    "\n",
    "'''\n",
    "\n",
    "ncdata = {}\n",
    "\n",
    "# the integer specifies how many _ fields to include\n",
    "# eg var/covar are functions of band and kernel so 4 variables, so 5\n",
    "specials = {\n",
    "    'Data_Mask_':2,\n",
    "    'Cov_':5,\n",
    "    'Mean_':2,\n",
    "    'VAR_':5,\n",
    "    'mean_':3,\n",
    "    'BB_':2,\n",
    "    'sig_BB_':4,\n",
    "    'Kgeo_BRDF':3,\n",
    "    'Kvol_BRDF':3,\n",
    "    'Kiso_BRDF':3\n",
    "}\n",
    "\n",
    "for k in datakeys:\n",
    "    k =  k.strip('/')\n",
    "    ncdata[k] = {}\n",
    "    print k\n",
    "    try:\n",
    "        ncdata[k] = load_obj(k)\n",
    "    except:\n",
    "        for i in xrange(len(ncfiles[k])):\n",
    "            ncfile = Dataset('./' +k+'/'+ncfiles[k][i],'r')         \n",
    "            for kk in np.sort(ncfile.variables.keys()):\n",
    "                # different data keys in different prior versions    \n",
    "                # Fix MEAN__BAND________\n",
    "                for terms in ['MEAN__BAND________']:\n",
    "                    thiskey = kk\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = 'MEAN_BAND_'+thiskey.split(terms)[1:]\n",
    "                        # eg 0_PARAMETER_F0_0000001_000000\n",
    "                        \n",
    "                # default\n",
    "                thiskey = kk.split('_1_')[0]\n",
    "                \n",
    "                # check if its in the specials\n",
    "                for terms in specials.keys():\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:specials[terms]])\n",
    "\n",
    "                # time - specific examples for hooks into time field\n",
    "                for terms in ['Cov_NIR_f0_NIR_f0','VAR_NIR_f0_NIR_f0','BB_NIR',\\\n",
    "                             'MODIS_Grid_1km_2D_Data_Fields_Range']:\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        doy = int(kk.split('_')[-2])\n",
    "                        if ('doy' not in ncdata[k]):\n",
    "                            print 'TIME'\n",
    "                            ncdata[k]['doy'] = []\n",
    "                        ncdata[k]['doy'].append(doy)\n",
    "                    \n",
    "                # other quite special ones, but all of a pattern\n",
    "                # e.g. Snow_Fraction_XXX -> Snow_Fraction\n",
    "                for terms in ['Snow_Fraction','Goodness_of_Fit','cloud_classif_flags','aot_flags',\\\n",
    "                             'snow_mask','RAA','SZA','VZA']:\n",
    "                    # prior\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                        \n",
    "                # ignore these ones\n",
    "                dontdoit = False\n",
    "                for terms in ['Weighted_Number_of_Samples', 'Entropy', 'lat', 'lon',\\\n",
    "                             'Goodness_of_Fit','Relative_Entropy','Time_to_the_Closest_Sample',\\\n",
    "                             'AOD550','DEM','NDVI','SM','sig_AOD550','sig_NDVI',\\\n",
    "                             'Proportion_NSamples','l1_flags',\\\n",
    "                              'MODIS_Grid_1km_2D_Data_Fields_num_observations_1km',\\\n",
    "                             'MODIS_Grid_500m_2D_Data_Fields_num_observations_500m']:\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        dontdoit = True\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                if not dontdoit:\n",
    "                    if (thiskey not in ncdata[k]):\n",
    "                        print k,thiskey,\";\",\n",
    "                        ncdata[k][thiskey] = []\n",
    "                    # read the data\n",
    "                    thisdata = ncfile.variables[kk][:]\n",
    "                    ncdata[k][thiskey].append(thisdata)\n",
    "            del ncfile\n",
    "        save_obj(ncdata[k],k)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbdr.flags\n",
      "bbdr.meris \tdate\n",
      "bbdr.vgt \tdate\n",
      "ga.brdf.merge \tdate\n",
      "ga.brdf.nosnow \tdate\n",
      "ga.brdf.snow \tdate\n",
      "mod09 \tdate\n",
      "myd09 \tdate\n",
      "prior.v2.nosnow\n",
      "prior.v2.snow\n",
      "prior.v2.snownosnow\n"
     ]
    }
   ],
   "source": [
    "# sort doys\n",
    "for k in datakeys:\n",
    "    print k,\n",
    "    # prior has doy only\n",
    "    if k[:5] != 'prior' and ('doy' in ncdata[k].keys()):\n",
    "        print '\\tdate'\n",
    "        ncdata[k]['date'] = np.atleast_1d(np.zeros(0))\n",
    "        ncdata[k]['yeardoy'] = np.array([ [int(str(i)[:4]),int(str(i)[4:])] for i in ncdata[k]['doy']])\n",
    "        for year,doy in ncdata[k]['yeardoy']:\n",
    "            ncdata[k]['date'] = np.append(ncdata[k]['date'],\\\n",
    "                                          datetime.date(year, 1, 1) + datetime.timedelta(days=doy))\n",
    "    else:\n",
    "        print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modis QA mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'MODIS_Grid_1km_2D_Data_Fields_SensorZenith', u'MODIS_Grid_500m_2D_Data_Fields_q_scan', u'MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth', 'yeardoy', u'MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth', u'MODIS_Grid_500m_2D_Data_Fields_obscov_500m', u'MODIS_Grid_500m_2D_Data_Fields_iobs_res', u'MODIS_Grid_1km_2D_Data_Fields_SolarZenith', u'MODIS_Grid_1km_2D_Data_Fields_Range', u'MODIS_Grid_1km_2D_Data_Fields_orbit_pnt', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b07', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b06', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b05', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b04', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b03', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b02', u'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01', u'MODIS_Grid_1km_2D_Data_Fields_state_1km', u'MODIS_Grid_1km_2D_Data_Fields_granule_pnt', 'date', u'MODIS_Grid_1km_2D_Data_Fields_gflags', 'doy', u'MODIS_Grid_500m_2D_Data_Fields_QC_500m']\n"
     ]
    }
   ],
   "source": [
    "# The following keys are available for the MODIS datasets\n",
    "\n",
    "print ncdata['mod09'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MODIS QA mask for this product is specified on the [USGS site](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod09a1).\n",
    "\n",
    "Here, we will decode `MODIS_Grid_500m_2D_Data_Fields_QC_500m`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'> <type 'numpy.ndarray'> int32 1002159035 1107296257 1073741824 1610612736 1073741824\n",
      "<type 'list'> <type 'numpy.ndarray'> int16 136 1033 1802 72 1033\n",
      "<type 'list'> <type 'numpy.ndarray'> int16 -28672 7007 1064 357 3696\n",
      "<type 'numpy.ndarray'> <type 'numpy.uint32'> uint32 1002159035 1107296257 1073741824 1610612736 1073741824\n",
      "<type 'numpy.ndarray'> <type 'numpy.uint16'> uint16 136 1033 1802 72 1033\n",
      "<type 'numpy.ndarray'> <type 'numpy.float64'> float64 -2.8672 0.7007 0.1064 0.0357 0.3696\n",
      "\n",
      "There are 0 values with the fill 4294967295\n",
      "\n",
      "\n",
      "There are 14 values with the fill 65535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa = ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']\n",
    "qa2 = ncdata['mod09']['MODIS_Grid_1km_2D_Data_Fields_state_1km']\n",
    "r = ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01']\n",
    "\n",
    "# print some info and examples\n",
    "qa_ = np.array(qa).astype(np.uint32).flatten()\n",
    "qa2_ = np.array(qa2).astype(np.uint16).flatten()\n",
    "r_ = np.array(r).astype(np.int16).flatten() * 0.0001\n",
    "\n",
    "for v in [qa,qa2,r]:\n",
    "    print type(v),type(v[0]),v[0].dtype,v[0][0][0],v[1][0][0],v[2][0][0],v[3][0][0],v[4][0][0]\n",
    "\n",
    "for v in [qa_,qa2_,r_]:\n",
    "    print type(v),type(v[0]),v[0].dtype,v[0],v[1],v[2],v[3],v[4]\n",
    "\n",
    "# 136?\n",
    "qcstr = '8 72 136 200 1032 1288 2056 2120 2184 2248'\n",
    "\n",
    "# The fill value is 4294967295\n",
    "# so lets see how many of these we have\n",
    "print '\\nThere are',(np.array(qa).flatten() == 4294967295).sum(),'values with the fill 4294967295\\n'\n",
    "print '\\nThere are',(qa2_ == 65535).sum(),'values with the fill 65535\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The 32bit unsigned varaible `MOD09A1.005 500-meter Surface Reflectance Data QA Descriptions` identifies the following bit fields:\n",
    "\n",
    "`[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]]`\n",
    "\n",
    "where each pair indicates the first and last significant bit of the relevant bitfield.\n",
    "\n",
    "We need to form a mask of each of these, where the bits in the mask are set to `1` over the bit range indicated and `0` elsewhere. Python code to explore such things can be found in [Lewis (2016)](http://nbviewer.jupyter.org/github/profLewis/geogg122/blob/master/Chapter2_Python_intro/advanced.ipynb).\n",
    "\n",
    "If $i$ and $j$ are the minimum and maximum bits of a particular bitfield, then, we calculate the number of bits involved \n",
    "\n",
    "$$\n",
    "l = j - i\n",
    "$$\n",
    "\n",
    "The mask then is given by:\n",
    "\n",
    "$$\n",
    "2^{(l+1)}-1 << i\n",
    "$$\n",
    "\n",
    "where $<<$ is a left bitshift operation.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maskbits = np.array([[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]])\n",
    "\n",
    "# some test values to decode\n",
    "test = np.array([1002159035,1107296257,1073741824]).astype(np.uint32).T\n",
    "\n",
    "# initial size 0 array\n",
    "modmask = np.atleast_1d(np.zeros(0)).astype(np.uint32)\n",
    "\n",
    "for t in test[0:2]:\n",
    "    print 'data',bin(t)\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if l == 3:\n",
    "            # 4 bit fields: reflectance quality\n",
    "            modmask = np.append(modmask,(2**(l+1)-1 << minbit))\n",
    "            print '\\tmask',l,bin(modmask[-1]),(t & modmask[-1]) >> minbit\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that for the 4-bit fields (band quality) `14` (that appears often in the first test) corresponds to `0b1110` which is interpreted as `L1B data faulty`.\n",
    "\n",
    "Similarly, `0` (that appears often in the second test) corresponds to `0b0000` which means `highest quality`. The `8` value (`0b1000`) means `dead detector; data interpolated in L1B`.\n",
    "\n",
    "The QA information we use will be to allow `0b0000` and `0b1000` fields to pass. If, for any waveband, the QA is not one of these, we reject the data.\n",
    "\n",
    "We also reject data that does not have a full clearance on bits 0, 30 and 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def good_qa(t,good4=[0,8]):\n",
    "    maskbits = np.array([[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]])\n",
    "    t = np.uint32(t)\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if l == 3:\n",
    "            # all of the 4 bit ones\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode not in good4:\n",
    "                return False\n",
    "        if minbit == 0:\n",
    "            # special case 1\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                return False\n",
    "        if minbit > 30:\n",
    "            # special case 2,3\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def modis_qa(tt,good4=[0,8]):\n",
    "    # work on array\n",
    "    tt = np.array(tt)\n",
    "    out = np.ones_like(tt).astype(bool)\n",
    "    for i,t in enumerate(tt):\n",
    "        out[i] = good_qa(t,good4=good4)\n",
    "    return out\n",
    "        \n",
    "print modis_qa([1002159035,1107296257,1073741824])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the QA field `MODIS_Grid_1km_2D_Data_Fields_state_1km` we take a similar approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def good_qa2(t,snow=False):\n",
    "    t = np.uint16(t)\n",
    "    retval = True\n",
    "    \n",
    "    maskbits = np.array([[0,1],[2,2],[3,5],[6,7],[8,9],[10,10],[11,11],[12,12],[13,12],[14,14],[15,15]])\n",
    "    # cloud, cirrus, shadow, adj\n",
    "    passers = np.array([0,2,8,13])\n",
    "\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if minbit in passers:\n",
    "            # special cases\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                retval = False\n",
    "            \n",
    "        snowed = False\n",
    "        #if minbit in [12,15]:\n",
    "        if minbit in [15]:\n",
    "            # snow tests\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode == 1:\n",
    "                snowed = True    \n",
    "    \n",
    "    return retval and ((snow and snowed) or (not snow and not snowed))\n",
    "\n",
    "def modis_qa2(tt,snow=False):\n",
    "    # work on array\n",
    "    tt = np.array(tt)\n",
    "    out = np.ones_like(tt).astype(bool)\n",
    "    for i,t in enumerate(tt):\n",
    "        out[i] = good_qa2(t,snow=snow)\n",
    "    return out\n",
    "\n",
    "test2 = np.array([8394, 1033, 1801])\n",
    "print modis_qa2(test2,snow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrow to broadband conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use linear equatiuons of the form:\n",
    "\n",
    "$$\n",
    "B = w^T b\n",
    "$$\n",
    "\n",
    "where vector $B$ has 3 broad wavebands, $b$ is a vector of the 7 MODIS bands, and $w$ is the weighting matrix.\n",
    "\n",
    "We also have an uncertainty matrix for the MODIS observations, following Roy et al. (2005) RSE 97: 137-162.\n",
    "\n",
    "We use the narrow to broadband coefficients of [Liang, 2000](https://www.google.co.uk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiOzKrEvYzLAhVBURoKHd7ECxIQFggiMAA&url=http%3A%2F%2Fterpconnect.umd.edu%2F~sliang%2Fpapers%2FRSE.N2B.1.pdf&usg=AFQjCNFDnawdSlcNvMTkNTSdSr447wfbnA&sig2=7SFNU8MS65X9aaVBtv30ow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute modis weights from Roy et al. (2005) RSE 97: 137-162\n",
    "modissd = np.array([0.004, 0.015, 0.003, 0.004, 0.013, 0.010, 0.006])\n",
    "\n",
    "RI = np.matrix(np.diag(modissd*modissd)).I\n",
    "\n",
    "bands = ['VIS','NIR','SW']\n",
    "\n",
    "# modis narrow to broadband coefficients from Liang, 2000\n",
    "BBweights = np.array([[0.331,0.000, 0.424,0.246,0.000,0.000,0.000, 0.0000],\\\n",
    "                      [0.039,0.504,-0.071,0.105,0.252,0.069,0.101, 0.0000],\\\n",
    "                      [0.160,0.291, 0.243,0.116,0.112,0.000,0.081,-0.0015]])\n",
    "\n",
    "# renormalise\n",
    "#BBweights = (BBweights.T / BBweights.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# form the subset of the weights matrix\n",
    "H = np.matrix(BBweights[:,:-1]).T\n",
    "\n",
    "# then the uncertainty (4x4 matrix) is\n",
    "BBuncertainty_weight = (H.T * RI * H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort MODIS data\n",
    "for k in ncdata.keys():\n",
    "    # MODIS processing\n",
    "    #\n",
    "    # reflectance observations\n",
    "    monkey = 'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b%02d'\n",
    "    monkey1 = monkey%1\n",
    "    if monkey1 in ncdata[k].keys():\n",
    "        print k\n",
    "\n",
    "        modiswt = 1./(modissd*modissd)\n",
    "        print '\\tobs:',k,len(ncdata[k][monkey1])\n",
    "        ncdata[k]['reflectance'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        ncdata[k]['weight'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        for i in xrange(1,8):\n",
    "            ncdata[k]['reflectance'][i-1,:] = np.array(ncdata[k][monkey%i]).squeeze().astype(float) * 0.0001\n",
    "            ncdata[k]['weight'][i-1,:] = modiswt[i-1]\n",
    "\n",
    "            # apply the linear model to the mean\n",
    "            BBrefl = (np.dot(BBweights[:,:-1],ncdata[k]['reflectance']).T + BBweights[:,-1]).T\n",
    "            # narrow to broadband\n",
    "            ncdata[k]['BB_VIS'] = BBrefl[0]\n",
    "            ncdata[k]['BB_VIS_DIR'] = BBrefl[1]\n",
    "            ncdata[k]['BB_NIR'] = BBrefl[2]\n",
    "            ncdata[k]['BB_SW']  = BBrefl[3]\n",
    "            \n",
    "            # uncertainty\n",
    "            #BBweight = np.dot(BBweights[:,:-1],ncdata[k]['weight'])\n",
    "            for b1,band1 in enumerate(['VIS','VIS_DIR','NIR','SW']):\n",
    "                for b2,band2 in enumerate(['VIS','VIS_DIR','NIR','SW']):\n",
    "                    if b2 <= b1:\n",
    "                        term = 'weight_BB_%s_%s'%(band1,band2)\n",
    "                        ncdata[k][term] = BBuncertainty_weight[b1,b2]\n",
    "\n",
    "            # extract qa\n",
    "            test = np.array(ncdata[k]['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze()\n",
    "            test2 = np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_state_1km']).squeeze()\n",
    "            ncdata[k]['mask'] = modis_qa(test,good4=[0,8])\n",
    "            ncdata[k]['mask_snow'] = modis_qa2(test2,snow=True)\n",
    "            ncdata[k]['mask_nosnow'] = modis_qa2(test2,snow=False)\n",
    "            # obscov - use as a weighting term?\n",
    "            ncdata[k]['obscov'] = 0.01*np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_obscov_500m']).squeeze().astype(float)\n",
    "\n",
    "            # angles\n",
    "            vza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorZenith']).squeeze().astype(float)\n",
    "            sza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarZenith']).squeeze().astype(float)\n",
    "            vaa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth']).squeeze().astype(float)\n",
    "            saa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth']).squeeze().astype(float)\n",
    "            kern = kernels.Kernels(vza, sza, vaa-saa, doIntegrals=False, RossHS=False, RossType='Thick',\\\n",
    "                     LiType='Sparse', normalise=1, nbar=0., RecipFlag=True, MODISSPARSE=True)\n",
    "\n",
    "            ncdata[k]['Kvol'],ncdata[k]['Kgeo'] = np.asarray(kern.Ross),np.asarray(kern.Li)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine MODIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the MODIS broad band reflectance data.\n",
    "\n",
    "We can look in particular at whether the two formulae given by Liang for direct and diffuse effects make any real difference.\n",
    "\n",
    "We can also examine the quality and quantity of snow and no snow data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR','NIR','SW']\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for mod in ['mod09']:\n",
    "    for i in xrange(4):\n",
    "        mm = ncdata[mod]['mask_snow']\n",
    "        x = ncdata[mod]['date'][mm]\n",
    "        y = ncdata[mod]['BB_%s'%bands[i]][mm]\n",
    "        w = ncdata[mod]['weight_BB_%s_%s'%(bands[i],bands[i])]\n",
    "        unc =  np.sqrt(1/w)\n",
    "        print unc\n",
    "        plt.plot(x,y,'+',label=mod+bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('snow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR','NIR','SW']\n",
    "bands = ['NIR']\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for i in xrange(len(bands)):\n",
    "    mm = ncdata['myd09']['mask_nosnow']\n",
    "    x = ncdata['myd09']['date'][mm]\n",
    "    y = ncdata['myd09']['BB_%s'%bands[i]][mm]\n",
    "    plt.plot(x,y,'+',label=bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('myd no snow')\n",
    "print ncdata['myd09']['date'].shape,ncdata['myd09']['mask_snow'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR']\n",
    "mm = ncdata['myd09']['mask_nosnow']\n",
    "plt.figure(figsize=(7,7))\n",
    "y0 = ncdata['myd09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['myd09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "\n",
    "mm = ncdata['mod09']['mask_nosnow']\n",
    "y0 = ncdata['mod09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['mod09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "\n",
    "plt.xlabel('diffuse VIS')\n",
    "plt.ylabel('direct VIS')\n",
    "plt.legend(loc='best')\n",
    "plt.title('no snow')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR']\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "mm = ncdata['myd09']['mask_snow']\n",
    "y0 = ncdata['myd09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['myd09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "mm = ncdata['mod09']['mask_snow']\n",
    "y0 = ncdata['mod09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['mod09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "plt.xlabel('diffuse VIS')\n",
    "plt.ylabel('direct VIS')\n",
    "plt.legend(loc='best')\n",
    "plt.title('snow')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa = 0b11\n",
    "\n",
    "np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze() & qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BBrefl = (np.dot(BBweights[:,:-1],ncdata['mod09']['reflectance']).T + BBweights[:,-1]).T\n",
    "print ncdata['mod09']['reflectance'].shape,BBrefl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 'mod09'\n",
    "for kk in ncdata[k].keys():\n",
    "    print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yeardoy = np.array([ [int(str(i)[:4]),int(str(i)[4:])] for i in ncdata['mod09']['doy']])\n",
    "\n",
    "\n",
    "np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze().astype(np.uint32).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
