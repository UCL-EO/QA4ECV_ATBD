{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobAlbedo and associated algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P. Lewis and M. van Leeuwen, UCL/NCEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first notebook deals with downloading the data from the database and constructing suitable data structures.\n",
    "\n",
    "The various forms of (netcdf) inputs are read and the data organised as a set of arrays in set of dictionaries.\n",
    "\n",
    "These dictionaries are then 'pickled' (saved to disk) for direct use in further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data directory /Users/plewis/QA4ECV_ATBD/data\n"
     ]
    }
   ],
   "source": [
    "from defaults import *\n",
    "%matplotlib inline\n",
    "db = 'http://gws-access.cems.rl.ac.uk/public/globalbedo/.stackXY2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to http://gws-access.cems.rl.ac.uk/public/globalbedo/.stackXY2/\n",
      "got urls\n",
      "prior.v1.nosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . prior.v1.snow2/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ga.brdf.snow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbdr.vgt/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . prior.v2.snownosnow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbdr.flags/\n",
      "prior.v2.snow/\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ga.brdf.merge/\n",
      ". . . . . . . . . . . . . . . . . . . . . "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Contact the server for a listing and \n",
    "if doit is True download the files and pack into\n",
    "the dictionary ncfiles. \n",
    "\n",
    "Actually, all we really need (to access pre-stored pickle files)\n",
    "is to set the variable  `datakeys`\n",
    "'''\n",
    "\n",
    "doit = True\n",
    "# set True if you want to download as well\n",
    "ncfiles = obtain_data(db,doit=doit)\n",
    "datakeys = ncfiles.keys()\n",
    "\n",
    "print np.sort(datakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# actually, we only want these particular datasets\n",
    "datakeys = np.array(['bbdr.flags', 'bbdr.meris', 'bbdr.vgt', 'ga.brdf.merge',\\\n",
    "       'ga.brdf.nosnow', 'ga.brdf.snow', 'mod09', 'myd09',\\\n",
    "       'prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow'])\n",
    "\n",
    "print np.sort(datakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Form the data dictionary (in ncdata), reading and storing each of the\n",
    "datasets in datakeys.\n",
    "\n",
    "The only complexities in the code are to do with correcting some variants\n",
    "(e.g. 'MEAN__BAND________' -> 'MEAN_BAND')\n",
    "\n",
    "The default parsing splits the key on _1_:\n",
    "\n",
    "thiskey = kk.split('_1_')[0]\n",
    "\n",
    "A set of 'special' keys are defined that need to be split / interpreted differently\n",
    "These are specified in the dictionary specials, with the key name and an integer specifying\n",
    "how many terms to include.\n",
    "\n",
    "To decode the TIME field, we look at the keys for\n",
    "'Cov_NIR_f0_NIR_f0','VAR_NIR_f0_NIR_f0','BB_NIR','MODIS_Grid_1km_2D_Data_Fields_Range'\n",
    "any one of which can lead to the time field.\n",
    "\n",
    "'''\n",
    "\n",
    "ncdata = {}\n",
    "\n",
    "# the integer specifies how many _ fields to include\n",
    "# eg var/covar are functions of band and kernel so 4 variables, so 5\n",
    "specials = {\n",
    "    'Data_Mask_':2,\n",
    "    'Cov_':5,\n",
    "    'Mean_':2,\n",
    "    'VAR_':5,\n",
    "    'mean_':3,\n",
    "    'BB_':2,\n",
    "    'sig_BB_':4,\n",
    "    'Kgeo_BRDF':3,\n",
    "    'Kvol_BRDF':3,\n",
    "    'Kiso_BRDF':3\n",
    "}\n",
    "\n",
    "for k in datakeys:\n",
    "    k =  k.strip('/')\n",
    "    ncdata[k] = {}\n",
    "    print k\n",
    "    try:\n",
    "        ncdata[k] = load_obj(k)\n",
    "    except:\n",
    "        for i in xrange(len(ncfiles[k])):\n",
    "            ncfile = Dataset('./' +k+'/'+ncfiles[k][i],'r')         \n",
    "            for kk in np.sort(ncfile.variables.keys()):\n",
    "                # different data keys in different prior versions    \n",
    "                # Fix MEAN__BAND________\n",
    "                for terms in ['MEAN__BAND________']:\n",
    "                    thiskey = kk\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = 'MEAN_BAND_'+thiskey.split(terms)[1:]\n",
    "                        # eg 0_PARAMETER_F0_0000001_000000\n",
    "                        \n",
    "                # default\n",
    "                thiskey = kk.split('_1_')[0]\n",
    "                \n",
    "                # check if its in the specials\n",
    "                for terms in specials.keys():\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:specials[terms]])\n",
    "\n",
    "                # time - specific examples for hooks into time field\n",
    "                for terms in ['Cov_NIR_f0_NIR_f0','VAR_NIR_f0_NIR_f0','BB_NIR',\\\n",
    "                             'MODIS_Grid_1km_2D_Data_Fields_Range']:\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        doy = int(kk.split('_')[-2])\n",
    "                        if ('doy' not in ncdata[k]):\n",
    "                            print 'TIME'\n",
    "                            ncdata[k]['doy'] = []\n",
    "                        ncdata[k]['doy'].append(doy)\n",
    "                    \n",
    "                # other quite special ones, but all of a pattern\n",
    "                # e.g. Snow_Fraction_XXX -> Snow_Fraction\n",
    "                for terms in ['Snow_Fraction','Goodness_of_Fit','cloud_classif_flags','aot_flags',\\\n",
    "                             'snow_mask','RAA','SZA','VZA']:\n",
    "                    # prior\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                        \n",
    "                # ignore these ones\n",
    "                dontdoit = False\n",
    "                for terms in ['Weighted_Number_of_Samples', 'Entropy', 'lat', 'lon',\\\n",
    "                             'Goodness_of_Fit','Relative_Entropy','Time_to_the_Closest_Sample',\\\n",
    "                             'AOD550','DEM','NDVI','SM','sig_AOD550','sig_NDVI',\\\n",
    "                             'Proportion_NSamples','l1_flags',\\\n",
    "                              'MODIS_Grid_1km_2D_Data_Fields_num_observations_1km',\\\n",
    "                             'MODIS_Grid_500m_2D_Data_Fields_num_observations_500m']:\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        dontdoit = True\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                if not dontdoit:\n",
    "                    if (thiskey not in ncdata[k]):\n",
    "                        print k,thiskey,\";\",\n",
    "                        ncdata[k][thiskey] = []\n",
    "                    # read the data\n",
    "                    thisdata = ncfile.variables[kk][:]\n",
    "                    ncdata[k][thiskey].append(thisdata)\n",
    "            del ncfile\n",
    "        save_obj(ncdata[k],'obj/'+k+'_s1.0_')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort doys\n",
    "for k in datakeys:\n",
    "    print k,\n",
    "    # prior has doy only\n",
    "    if k[:5] != 'prior' and ('doy' in ncdata[k].keys()):\n",
    "        print '\\tdate'\n",
    "        ncdata[k]['date'] = np.atleast_1d(np.zeros(0))\n",
    "        ncdata[k]['yeardoy'] = np.array([ [int(str(i)[:4]),int(str(i)[4:])] for i in ncdata[k]['doy']])\n",
    "        for year,doy in ncdata[k]['yeardoy']:\n",
    "            ncdata[k]['date'] = np.append(ncdata[k]['date'],\\\n",
    "                                          datetime.date(year, 1, 1) + datetime.timedelta(days=doy))\n",
    "    else:\n",
    "        print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modis QA mask\n",
    "\n",
    "![alt text][qatxt]\n",
    "\n",
    "[qatxt]: qatable.png \"https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod09a1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following keys are available for the MODIS datasets\n",
    "\n",
    "print ncdata['mod09'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MODIS QA mask for this product is specified on the [USGS site](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod09a1).\n",
    "\n",
    "Here, we will decode `MODIS_Grid_1km_2D_Data_Fields_state_1km`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa = ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']\n",
    "qa2 = ncdata['mod09']['MODIS_Grid_1km_2D_Data_Fields_state_1km']\n",
    "r = ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01']\n",
    "\n",
    "# print some info and examples\n",
    "qa_ = np.array(qa).astype(np.uint32).flatten()\n",
    "qa2_ = np.array(qa2).astype(np.uint16).flatten()\n",
    "r_ = np.array(r).astype(np.int16).flatten() * 0.0001\n",
    "\n",
    "names = ['MODIS_Grid_500m_2D_Data_Fields_QC_500m','MODIS_Grid_1km_2D_Data_Fields_state_1km',\\\n",
    "         'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b01']\n",
    "\n",
    "for i,v in enumerate([qa,qa2,r]):\n",
    "    print names[i],type(v),type(v[0]),v[0].dtype,\n",
    "    for i in xrange(10):\n",
    "        print v[i][0][0],\n",
    "    print\n",
    "\n",
    "for i,v in enumerate([qa_,qa2_,r_]):\n",
    "    print names[i],type(v),type(v[0]),v[0].dtype,\n",
    "    for i in xrange(10):\n",
    "        print v[i],\n",
    "    print \n",
    "    \n",
    "# The fill value is 4294967295\n",
    "# so lets see how many of these we have\n",
    "'''\n",
    "for i in np.sort(np.array(np.unique(qa2_)).astype(int)):\n",
    "    print 'There are',(qa2_ == i).sum(),'values with value %d'%i,bin(i)\n",
    "    print r_[qa2_ == i]\n",
    "    print '========================'\n",
    "'''\n",
    "    \n",
    "    \n",
    "# 136?\n",
    "\n",
    "qcstr = ''\n",
    "# lets look at the 2 bits that tell us clear\n",
    "bitmask = 2**6-1\n",
    "for i in np.sort(np.unique(qa2_).astype(np.uint16)):\n",
    "    m = i & bitmask\n",
    "    '''\n",
    "     clear, land (NB - land only!)\n",
    "     bit 10 : internal cloud algorithm flag  -- trust this\n",
    "     bit 13 : Pixel is adjacent to cloud -- best not use if possible\n",
    "     bit 12 : MOD35 snow/ice flag -- exclude snow in this test\n",
    "     bit 2: cloud shadow - trust this\n",
    "     bit 15 : internal snow algorithm -- exclude snow in this test\n",
    "    '''\n",
    "    if m == 0b001000:\n",
    "        if not (((i & 2**10)>>10) or ((i & 2**13)>>13) or ((i & 2**12)>>12) \\\n",
    "                or ((i & 2**2)>>2) or ((i & 2**15)>>15)): \n",
    "            '''\n",
    "            print '==========='\n",
    "            print i,bin(i)\n",
    "            print '==========='\n",
    "            for b in xrange(15):\n",
    "                print b,((i & 2**b)>>b)\n",
    "            '''\n",
    "            qcstr += ' ' + str(i)\n",
    "        \n",
    "#qcstr = '8 72 136 200 1032 1288 1544 1800 5128 5384 5640 5896 8264 8328 8392 9480 12488 32776 36872 45064'\n",
    "#qcstr = '8 72 136 200 1288 2056 2120 2184 2248'\n",
    "\n",
    "print 'valid:',qcstr\n",
    "# Mixed : \n",
    "#\n",
    "\n",
    "for i in np.sort(np.array(qcstr.split()).astype(np.uint16)):\n",
    "    print 'There are',(qa2_ == i).sum(),'values with value %d'%i,bin(i)\n",
    "    print r_[qa2_ == i]\n",
    "    print '========================'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def good_qa(t,good4=[0b001000],bitmask=2**6-1):\n",
    "    bitmask = 2**6-1\n",
    "    t = np.uint16(t)\n",
    "    m = t & bitmask\n",
    "    if m == 0b001000:\n",
    "        return True\n",
    "    \n",
    "def snow_qa(tt):\n",
    "    # bit 12 MOD35 snow/ice flag\n",
    "    # bit 15 internal snow algorithm flag\n",
    "    tt = np.uint16(np.array(tt))\n",
    "    s1 = (tt & 2**12)>>12\n",
    "    s2 = (tt & 2**15)>>15\n",
    "    snow = np.logical_or(s1,s2)\n",
    "    return snow\n",
    "\n",
    "goodqa = np.sort(np.array(qcstr.split()).astype(np.uint16))\n",
    "\n",
    "def modis_qa(tt,good=goodqa):\n",
    "    # work on array\n",
    "    tt = np.uint16(np.array(tt))\n",
    "    s0 = tt == good[0]\n",
    "    for g in good[1:]:\n",
    "        s0 = np.logical_or(s0,tt == g)\n",
    "    return s0\n",
    "\n",
    "def modis_qa_broken(tt,good4=[0b001000],bitmask=2**6-1):\n",
    "    # work on array\n",
    "    tt = np.uint16(np.array(tt))\n",
    "    # land no cloud\n",
    "    s0 = (tt & bitmask) == good4[0]\n",
    "    '''\n",
    "     clear, land (NB - land only!)\n",
    "     bit 10 : internal cloud algorithm flag  -- trust this\n",
    "     bit 13 : Pixel is adjacent to cloud -- best not use if possible\n",
    "     bit 12 : MOD35 snow/ice flag -- exclude snow in this test\n",
    "     bit 2: cloud shadow - trust this\n",
    "     bit 15 : internal snow algorithm -- exclude snow in this test\n",
    "    '''    \n",
    "    for i in [10,13,12,2,15]:\n",
    "        s0 = np.logical_or(s0,(tt & 2**i)>>i)\n",
    "    return s0\n",
    "    \n",
    "#qcstr = '8 72 136 200 1032 1288 1544 1800 5128 5384 5640 5896 8264 8328 8392 9480 12488 32776 36872 45064'\n",
    "\n",
    "print qcstr\n",
    "tt = np.sort(np.array(qcstr.split()).astype(np.uint16))\n",
    "\n",
    "print 'snow        ',snow_qa(tt)\n",
    "print 'good        ',modis_qa(tt)\n",
    "print 'good no snow',np.logical_and(modis_qa(tt),~snow_qa(tt))\n",
    "print 'good snow   ',np.logical_and(modis_qa(tt),snow_qa(tt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrow to broadband conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use linear equations of the form:\n",
    "\n",
    "$$\n",
    "B = w^T b\n",
    "$$\n",
    "\n",
    "where vector $B$ has 3 broad wavebands, $b$ is a vector of the 7 MODIS bands, and $w$ is the weighting matrix.\n",
    "\n",
    "We also have an uncertainty matrix for the MODIS observations, following Roy et al. (2005) RSE 97: 137-162.\n",
    "\n",
    "We use the narrow to broadband coefficients of [Liang, 2000](https://www.google.co.uk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiOzKrEvYzLAhVBURoKHd7ECxIQFggiMAA&url=http%3A%2F%2Fterpconnect.umd.edu%2F~sliang%2Fpapers%2FRSE.N2B.1.pdf&usg=AFQjCNFDnawdSlcNvMTkNTSdSr447wfbnA&sig2=7SFNU8MS65X9aaVBtv30ow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute modis weights from Roy et al. (2005) RSE 97: 137-162\n",
    "modissd = np.array([0.004, 0.015, 0.003, 0.004, 0.013, 0.010, 0.006])\n",
    "\n",
    "RI = np.matrix(np.diag(modissd*modissd)).I\n",
    "\n",
    "bands = ['VIS','NIR','SW']\n",
    "\n",
    "# modis narrow to broadband coefficients from Liang, 2000\n",
    "BBweights = np.array([[0.331,0.000, 0.424,0.246,0.000,0.000,0.000, 0.0000],\\\n",
    "                      [0.039,0.504,-0.071,0.105,0.252,0.069,0.101, 0.0000],\\\n",
    "                      [0.160,0.291, 0.243,0.116,0.112,0.000,0.081,-0.0015]])\n",
    "\n",
    "# renormalise\n",
    "#BBweights = (BBweights.T / BBweights.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# form the subset of the weights matrix\n",
    "H = np.matrix(BBweights[:,:-1]).T\n",
    "\n",
    "# then the uncertainty (4x4 matrix) is\n",
    "BBuncertainty_weight = (H.T * RI * H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort MODIS data\n",
    "for k in ncdata.keys():\n",
    "    # MODIS processing\n",
    "    #\n",
    "    # reflectance observations\n",
    "    monkey = 'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b%02d'\n",
    "    monkey1 = monkey%1\n",
    "    if monkey1 in ncdata[k].keys():\n",
    "        print k\n",
    "\n",
    "        modiswt = 1./(modissd*modissd)\n",
    "        print '\\tobs:',k,len(ncdata[k][monkey1])\n",
    "        ncdata[k]['reflectance'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        ncdata[k]['weight'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        for i in xrange(1,8):\n",
    "            ncdata[k]['reflectance'][i-1,:] = np.array(ncdata[k][monkey%i]).squeeze().astype(float) * 0.0001\n",
    "            ncdata[k]['weight'][i-1,:] = modiswt[i-1]\n",
    "\n",
    "            # apply the linear model to the mean\n",
    "            BBrefl = (np.dot(BBweights[:,:-1],ncdata[k]['reflectance']).T + BBweights[:,-1]).T\n",
    "            # narrow to broadband\n",
    "            ncdata[k]['BB_VIS'] = BBrefl[0]\n",
    "            ncdata[k]['BB_NIR'] = BBrefl[1]\n",
    "            ncdata[k]['BB_SW']  = BBrefl[2]\n",
    "            \n",
    "            # uncertainty\n",
    "            #BBweight = np.dot(BBweights[:,:-1],ncdata[k]['weight'])\n",
    "            for b1,band1 in enumerate(['VIS','NIR','SW']):\n",
    "                for b2,band2 in enumerate(['VIS','NIR','SW']):\n",
    "                    if b2 <= b1:\n",
    "                        term = 'weight_BB_%s_%s'%(band1,band2)\n",
    "                        ncdata[k][term] = BBuncertainty_weight[b1,b2]\n",
    "\n",
    "                        \n",
    "            '''\n",
    "            'snow        ',snow_qa(tt)\n",
    "            'good        ',modis_qa(tt)\n",
    "            'good no snow',np.logical_and(modis_qa(tt),~snow_qa(tt))\n",
    "            'good snow   ',np.logical_and(modis_qa(tt),snow_qa(tt))\n",
    "            '''\n",
    "            # extract qa\n",
    "            #test = np.array(ncdata[k]['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze()\n",
    "            tt = np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_state_1km']).squeeze()\n",
    "            ncdata[k]['mask'] = modis_qa(tt)\n",
    "            ncdata[k]['mask_snow'] = np.logical_and(modis_qa(tt),snow_qa(tt))\n",
    "            ncdata[k]['mask_nosnow'] = np.logical_and(modis_qa(tt),~snow_qa(tt))\n",
    "            # obscov - use as a weighting term?\n",
    "            ncdata[k]['obscov'] = 0.01*np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_obscov_500m']).squeeze().astype(float)\n",
    "\n",
    "            # angles\n",
    "            vza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorZenith']).squeeze().astype(float)\n",
    "            sza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarZenith']).squeeze().astype(float)\n",
    "            vaa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth']).squeeze().astype(float)\n",
    "            saa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth']).squeeze().astype(float)\n",
    "            kern = kernels.Kernels(vza, sza, vaa-saa, doIntegrals=False, RossHS=False, RossType='Thick',\\\n",
    "                     LiType='Sparse', normalise=1, nbar=0., RecipFlag=True, MODISSPARSE=True)\n",
    "\n",
    "            ncdata[k]['Kvol'],ncdata[k]['Kgeo'] = np.asarray(kern.Ross),np.asarray(kern.Li)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine MODIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the MODIS broad band reflectance data.\n",
    "\n",
    "We can look in particular at whether the two formulae given by Liang for direct and diffuse effects make any real difference.\n",
    "\n",
    "We can also examine the quality and quantity of snow and no snow data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','NIR','SW']\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for mod in ['mod09','myd09']:\n",
    "    for i in xrange(3):\n",
    "        mm = ncdata[mod]['mask_nosnow']\n",
    "        x = ncdata[mod]['date'][mm]\n",
    "        y = ncdata[mod]['BB_%s'%bands[i]][mm]\n",
    "        w = ncdata[mod]['weight_BB_%s_%s'%(bands[i],bands[i])]\n",
    "        unc =  np.sqrt(1/w)\n",
    "        print unc\n",
    "        plt.plot(x,y,'+',label=mod+bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('no snow')\n",
    "plt.ylim(0,None)\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for mod in ['mod09','myd09']:\n",
    "    for i in xrange(3):\n",
    "        mm = ncdata[mod]['mask_snow']\n",
    "        x = ncdata[mod]['date'][mm]\n",
    "        y = ncdata[mod]['BB_%s'%bands[i]][mm]\n",
    "        w = ncdata[mod]['weight_BB_%s_%s'%(bands[i],bands[i])]\n",
    "        unc =  np.sqrt(1/w)\n",
    "        print unc\n",
    "        plt.plot(x,y,'+',label=mod+bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('snow')\n",
    "plt.ylim(0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save objects\n",
    "for k in datakeys:\n",
    "    print k\n",
    "    try:\n",
    "        save_obj(ncdata[k],'obj/'+k+'_s2.0_')\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
