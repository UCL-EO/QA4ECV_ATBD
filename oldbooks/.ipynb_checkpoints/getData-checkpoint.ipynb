{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobAlbedo and associated algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P. Lewis and M. van Leeuwen, UCL/NCEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we explore variations on the theme of the ESA GlobAlbedo algorithm.\n",
    "\n",
    "This first notebook deals with downloading the data from the database and constructing suitable data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import urllib2\n",
    "from HTMLParser import HTMLParser\n",
    "import os\n",
    "import pickle\n",
    "import kernels\n",
    "import datetime\n",
    "from datetime import date,timedelta\n",
    "\n",
    "\n",
    "db = 'http://gws-access.cems.rl.ac.uk/public/globalbedo/.stackXY2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Codes to pull netcdf files from the server\n",
    "\n",
    "'''\n",
    "# create a subclass and override the handler methods\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    # see https://docs.python.org/2/library/htmlparser.html\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        pass;\n",
    "        #print \"Encountered a start tag:\", tag\n",
    "    def handle_endtag(self, tag):\n",
    "        pass\n",
    "        #print \"Encountered an end tag :\", tag\n",
    "    def handle_data(self, data):\n",
    "        data = data.strip()\n",
    "        if len(data) and data[-1] == '/':\n",
    "            # is it a directory?\n",
    "            try:\n",
    "                self.datadirs.append(data)\n",
    "            except:\n",
    "                self.datadirs = [data]\n",
    "        if len(data) and data.split('.')[-1] == 'nc':\n",
    "            # is it a nc file?\n",
    "            try:\n",
    "                self.ncfiles.append(data)\n",
    "            except:\n",
    "                self.ncfiles = [data]            \n",
    "        \n",
    "def getdirs(db):\n",
    "    # get directories from url\n",
    "    response = urllib2.urlopen(db,None,120)\n",
    "    \n",
    "    parser = MyHTMLParser()\n",
    "    html = response.read()\n",
    "    del response\n",
    "    parser.feed(html)\n",
    "    return parser\n",
    "\n",
    "def nc_urls(db):\n",
    "    '''\n",
    "    obtain full list of data urls of nc files\n",
    "    '''\n",
    "    ncfiles = {}\n",
    "    parser = getdirs(db)\n",
    "    for sensor in parser.datadirs:\n",
    "        ncfiles[sensor] = []\n",
    "        parser2 = getdirs(db+sensor)\n",
    "        if hasattr(parser2, 'datadirs'):\n",
    "            for sub0 in parser2.datadirs:\n",
    "                parser3 = getdirs(db+sensor+sub0)\n",
    "                if hasattr(parser3, 'datadirs'):\n",
    "                    for sub1 in parser3.datadirs:\n",
    "                        parser4 = getdirs(db+sensor+sub0+sub1)\n",
    "                        if hasattr(parser4, 'datadirs'):\n",
    "                            print 'deepest level checked'\n",
    "                        if hasattr(parser4, 'ncfiles'):\n",
    "                            for nc in parser4.ncfiles:\n",
    "                                ncfiles[sensor].append(db+sensor+sub0+sub1+nc)\n",
    "                if hasattr(parser3, 'ncfiles'):\n",
    "                    for nc in parser3.ncfiles:\n",
    "                            ncfiles[sensor].append(db+sensor+sub0+nc)\n",
    "        if hasattr(parser2, 'ncfiles'):\n",
    "            for nc in parser2.ncfiles:\n",
    "                ncfiles[sensor].append(db+sensor+nc)\n",
    "    return ncfiles\n",
    "\n",
    "def ensure_dir(f):\n",
    "    d = os.path.dirname(f)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        \n",
    "def obtain_data(db,doit=True):\n",
    "    print 'connecting to',db\n",
    "    ncfiles = nc_urls(db)\n",
    "    print 'got urls'\n",
    "    nclocals = {}\n",
    "    datakeys = ncfiles.keys()\n",
    "    for k in datakeys:\n",
    "        print k\n",
    "        ensure_dir(k)\n",
    "        nclocals[k] = []\n",
    "        for ncfile in ncfiles[k]:\n",
    "            print '.',\n",
    "            if doit:\n",
    "                data = urllib2.urlopen(ncfile).read()\n",
    "            local = ncfile.split('/')[-1]\n",
    "            nclocals[k].append(local)\n",
    "            # write\n",
    "            if doit:\n",
    "                f = open(k+local,'wb')\n",
    "                f.write(data)\n",
    "                f.close()\n",
    "    for k in nclocals.keys():\n",
    "        if k[-1] == '/':\n",
    "            nclocals[k.strip('/')] = nclocals[k]\n",
    "            del nclocals[k]\n",
    "    return nclocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Contact the server for a listing and \n",
    "if doit is True download the files and pack into\n",
    "the dictionary ncfiles. \n",
    "\n",
    "Actually, all we really need (to access pre-stored pickle files)\n",
    "is to set the variable  `datakeys`\n",
    "'''\n",
    "\n",
    "doit = False\n",
    "# set True if you want to download as well\n",
    "\n",
    "if doit:\n",
    "    ncfiles = obtain_data(db,doit=doit)\n",
    "    datakeys = ncfiles.keys()\n",
    "else:\n",
    "    # this is most of them\n",
    "    datakeys = np.array(['bbdr.flags', 'bbdr.meris', 'bbdr.vgt', 'ga.brdf.merge',\\\n",
    "       'ga.brdf.nosnow', 'ga.brdf.snow', 'mod09', 'myd09',\\\n",
    "       'prior.v2.nosnow', 'prior.v2.snow', 'prior.v2.snownosnow'])\n",
    "#        'prior.v1.nosnow', 'prior.v1.snow1', 'prior.v1.snow2',\\\n",
    "\n",
    "print np.sort(datakeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_obj(obj, name ):\n",
    "    ensure_dir('obj/')\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "ncdata = {}\n",
    "\n",
    "# the integer specifies how many _ fields to include\n",
    "# eg var/covar are functions of band and kernel so 4 variables, so 5\n",
    "specials = {\n",
    "    'Data_Mask_':2,\n",
    "    'Cov_':5,\n",
    "    'Mean_':2,\n",
    "    'VAR_':5,\n",
    "    'mean_':3,\n",
    "    'BB_':2,\n",
    "    'sig_BB_':4,\n",
    "    'Kgeo_BRDF':3,\n",
    "    'Kvol_BRDF':3,\n",
    "    'Kiso_BRDF':3\n",
    "}\n",
    "\n",
    "for k in datakeys:\n",
    "    k = k.strip('/')\n",
    "    ncdata[k] = {}\n",
    "    print k\n",
    "    try:\n",
    "        ncdata[k] = load_obj(k)\n",
    "    except:\n",
    "        for i in xrange(len(ncfiles[k])):\n",
    "            ncfile = Dataset(k+'/'+ncfiles[k][i],'r')         \n",
    "            for kk in np.sort(ncfile.variables.keys()):\n",
    "                # different data keys in different prior versions    \n",
    "                for terms in ['MEAN__BAND________']:\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = 'MEAN_BAND_'+thiskey.split(terms)[1:]\n",
    "                        # eg 0_PARAMETER_F0_0000001_000000\n",
    "                        \n",
    "                # default\n",
    "                thiskey = kk.split('_1_')[0]\n",
    "                \n",
    "                # check if its in the specials\n",
    "                for terms in specials.keys():\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:specials[terms]])\n",
    "\n",
    "                # time - specific examples for hooks into time field\n",
    "                for terms in ['Cov_NIR_f0_NIR_f0','VAR_NIR_f0_NIR_f0','BB_NIR',\\\n",
    "                             'MODIS_Grid_1km_2D_Data_Fields_Range']:\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        doy = int(kk.split('_')[-2])\n",
    "                        if ('doy' not in ncdata[k]):\n",
    "                            print 'TIME'\n",
    "                            ncdata[k]['doy'] = []\n",
    "                        ncdata[k]['doy'].append(doy)\n",
    "                    \n",
    "                # other quite special ones, but all of a pattern\n",
    "                # e.g. Snow_Fraction_XXX -> Snow_Fraction\n",
    "                for terms in ['Snow_Fraction','Goodness_of_Fit','cloud_classif_flags','aot_flags',\\\n",
    "                             'snow_mask','RAA','SZA','VZA']:\n",
    "                    # prior\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                        \n",
    "\n",
    "                # ignore these ones\n",
    "                dontdoit = False\n",
    "                for terms in ['Weighted_Number_of_Samples', 'Entropy', 'lat', 'lon',\\\n",
    "                             'Goodness_of_Fit','Relative_Entropy','Time_to_the_Closest_Sample',\\\n",
    "                             'AOD550','DEM','NDVI','SM','sig_AOD550','sig_NDVI',\\\n",
    "                             'Proportion_NSamples','l1_flags',\\\n",
    "                              'MODIS_Grid_1km_2D_Data_Fields_num_observations_1km',\\\n",
    "                             'MODIS_Grid_500m_2D_Data_Fields_num_observations_500m']:\n",
    "                    nn = terms.count('_') + 1\n",
    "                    if thiskey[:len(terms)] == terms:\n",
    "                        dontdoit = True\n",
    "                        thiskey = '_'.join(kk.split('_')[:nn]) \n",
    "\n",
    "                if not dontdoit:\n",
    "                    if (thiskey not in ncdata[k]):\n",
    "                        print k,thiskey,\";\",\n",
    "                        ncdata[k][thiskey] = []\n",
    "                    # read the data\n",
    "                    thisdata = ncfile.variables[kk][:]\n",
    "                    ncdata[k][thiskey].append(thisdata)\n",
    "            del ncfile\n",
    "        save_obj(ncdata[k],k)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort doys\n",
    "for k in ncdata.keys():\n",
    "    print k,\n",
    "    # prior has doy only\n",
    "    if k[:5] != 'prior' and ('doy' in ncdata[k].keys()):\n",
    "        print '\\tdate'\n",
    "        ncdata[k]['date'] = np.atleast_1d(np.zeros(0))\n",
    "        ncdata[k]['yeardoy'] = np.array([ [int(str(i)[:4]),int(str(i)[4:])] for i in ncdata[k]['doy']])\n",
    "        for year,doy in ncdata[k]['yeardoy']:\n",
    "            ncdata[k]['date'] = np.append(ncdata[k]['date'],\\\n",
    "                                          datetime.date(year, 1, 1) + datetime.timedelta(days=doy))\n",
    "    else:\n",
    "        print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modis QA mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MODIS QA mask for this product is specified on the [USGS site](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod09a1).\n",
    "\n",
    "The 32bit unsigned varaible `MOD09A1.005 500-meter Surface Reflectance Data QA Descriptions` identifies the following bit fields:\n",
    "\n",
    "`[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]]`\n",
    "\n",
    "where each pair indicates the first and last significant bit of the relevant bitfield.\n",
    "\n",
    "We need to form a mask of each of these, where the bits in the mask are set to `1` over the bit range indicated and `0` elsewhere. Python code to explore such things can be found in [Lewis (2016)](http://nbviewer.jupyter.org/github/profLewis/geogg122/blob/master/Chapter2_Python_intro/advanced.ipynb).\n",
    "\n",
    "If $i$ and $j$ are the minimum and maximum bits of a particular bitfield, then, we calculate the number of bits involved \n",
    "\n",
    "$$\n",
    "l = j - i\n",
    "$$\n",
    "\n",
    "The mask then is given by:\n",
    "\n",
    "$$\n",
    "2^{(l+1)}-1 << i\n",
    "$$\n",
    "\n",
    "where $<<$ is a left bitshift operation.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maskbits = np.array([[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]])\n",
    "\n",
    "# some test values to decode\n",
    "test = np.array([1002159035,1107296257,1073741824]).astype(np.uint32).T\n",
    "\n",
    "# initial size 0 array\n",
    "modmask = np.atleast_1d(np.zeros(0)).astype(np.uint32)\n",
    "\n",
    "for t in test[0:2]:\n",
    "    print 'data',bin(t)\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if l == 3:\n",
    "            # 4 bit fields: reflectance quality\n",
    "            modmask = np.append(modmask,(2**(l+1)-1 << minbit))\n",
    "            print '\\tmask',l,bin(modmask[-1]),(t & modmask[-1]) >> minbit\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that for the 4-bit fields (band quality) `14` (that appears often in the first test) corresponds to `0b1110` which is interpreted as `L1B data faulty`.\n",
    "\n",
    "Similarly, `0` (that appears often in the second test) corresponds to `0b0000` which means `highest quality`. The `8` value (`0b1000`) means `dead detector; data interpolated in L1B`.\n",
    "\n",
    "The QA information we use will be to allow `0b0000` and `0b1000` fields to pass. If, for any waveband, the QA is not one of these, we reject the data.\n",
    "\n",
    "We also reject data that does not have a full clearance on bits 0, 30 and 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def good_qa(t,good4=[0,8]):\n",
    "    maskbits = np.array([[0,1],[2,5],[6,9],[10,13],[14,17],[18,21],[22,25],[26,29],[30,30],[31,31]])\n",
    "    t = np.uint32(t)\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if l == 3:\n",
    "            # all of the 4 bit ones\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode not in good4:\n",
    "                return False\n",
    "        if minbit == 0:\n",
    "            # special case 1\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                return False\n",
    "        if minbit > 30:\n",
    "            # special case 2,3\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def modis_qa(tt,good4=[0,8]):\n",
    "    # work on array\n",
    "    tt = np.array(tt)\n",
    "    out = np.ones_like(tt).astype(bool)\n",
    "    for i,t in enumerate(tt):\n",
    "        out[i] = good_qa(t,good4=good4)\n",
    "    return out\n",
    "        \n",
    "print modis_qa([1002159035,1107296257,1073741824])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the QA field `MODIS_Grid_1km_2D_Data_Fields_state_1km` we take a similar approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def good_qa2(t,snow=False):\n",
    "    t = np.uint16(t)\n",
    "    retval = True\n",
    "    \n",
    "    maskbits = np.array([[0,1],[2,2],[3,5],[6,7],[8,9],[10,10],[11,11],[12,12],[13,12],[14,14],[15,15]])\n",
    "    # cloud, cirrus, shadow, adj\n",
    "    passers = np.array([0,2,8,13])\n",
    "\n",
    "    for minbit,maxbit in maskbits:\n",
    "        l = maxbit-minbit\n",
    "        if minbit in passers:\n",
    "            # special cases\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode > 0:\n",
    "                retval = False\n",
    "            \n",
    "        snowed = False\n",
    "        #if minbit in [12,15]:\n",
    "        if minbit in [15]:\n",
    "            # snow tests\n",
    "            modmask = (2**(l+1)-1 << minbit)\n",
    "            decode = (t & modmask) >> minbit\n",
    "            if decode == 1:\n",
    "                snowed = True    \n",
    "    \n",
    "    return retval and ((snow and snowed) or (not snow and not snowed))\n",
    "\n",
    "def modis_qa2(tt,snow=False):\n",
    "    # work on array\n",
    "    tt = np.array(tt)\n",
    "    out = np.ones_like(tt).astype(bool)\n",
    "    for i,t in enumerate(tt):\n",
    "        out[i] = good_qa2(t,snow=snow)\n",
    "    return out\n",
    "\n",
    "test2 = np.array([8394, 1033, 1801])\n",
    "print modis_qa2(test2,snow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrow to broadband conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use linear equatiuons of the form:\n",
    "\n",
    "$$\n",
    "B = w^T b\n",
    "$$\n",
    "\n",
    "where vector $B$ has 3 broad wavebands, $b$ is a vector of the 7 MODIS bands, and $w$ is the weighting matrix.\n",
    "\n",
    "We also have an uncertainty matrix for the MODIS observations, following Roy et al. (2005) RSE 97: 137-162.\n",
    "\n",
    "We use the narrow to broadband coefficients of [Liang, 2000](https://www.google.co.uk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiOzKrEvYzLAhVBURoKHd7ECxIQFggiMAA&url=http%3A%2F%2Fterpconnect.umd.edu%2F~sliang%2Fpapers%2FRSE.N2B.1.pdf&usg=AFQjCNFDnawdSlcNvMTkNTSdSr447wfbnA&sig2=7SFNU8MS65X9aaVBtv30ow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute modis weights from Roy et al. (2005) RSE 97: 137-162\n",
    "modissd = np.array([0.004, 0.015, 0.003, 0.004, 0.013, 0.010, 0.006])\n",
    "\n",
    "RI = np.matrix(np.diag(modissd*modissd)).I\n",
    "\n",
    "bands = ['VIS','NIR','SW']\n",
    "\n",
    "# modis narrow to broadband coefficients from Liang, 2000\n",
    "BBweights = np.array([[0.331,0.000, 0.424,0.246,0.000,0.000,0.000, 0.0000],\\\n",
    "                      [0.039,0.504,-0.071,0.105,0.252,0.069,0.101, 0.0000],\\\n",
    "                      [0.160,0.291, 0.243,0.116,0.112,0.000,0.081,-0.0015]])\n",
    "\n",
    "# renormalise\n",
    "#BBweights = (BBweights.T / BBweights.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# form the subset of the weights matrix\n",
    "H = np.matrix(BBweights[:,:-1]).T\n",
    "\n",
    "# then the uncertainty (4x4 matrix) is\n",
    "BBuncertainty_weight = (H.T * RI * H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort MODIS data\n",
    "for k in ncdata.keys():\n",
    "    # MODIS processing\n",
    "    #\n",
    "    # reflectance observations\n",
    "    monkey = 'MODIS_Grid_500m_2D_Data_Fields_sur_refl_b%02d'\n",
    "    monkey1 = monkey%1\n",
    "    if monkey1 in ncdata[k].keys():\n",
    "        print k\n",
    "\n",
    "        modiswt = 1./(modissd*modissd)\n",
    "        print '\\tobs:',k,len(ncdata[k][monkey1])\n",
    "        ncdata[k]['reflectance'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        ncdata[k]['weight'] = np.zeros((7,len(ncdata[k][monkey1])))\n",
    "        for i in xrange(1,8):\n",
    "            ncdata[k]['reflectance'][i-1,:] = np.array(ncdata[k][monkey%i]).squeeze().astype(float) * 0.0001\n",
    "            ncdata[k]['weight'][i-1,:] = modiswt[i-1]\n",
    "\n",
    "            # apply the linear model to the mean\n",
    "            BBrefl = (np.dot(BBweights[:,:-1],ncdata[k]['reflectance']).T + BBweights[:,-1]).T\n",
    "            # narrow to broadband\n",
    "            ncdata[k]['BB_VIS'] = BBrefl[0]\n",
    "            ncdata[k]['BB_VIS_DIR'] = BBrefl[1]\n",
    "            ncdata[k]['BB_NIR'] = BBrefl[2]\n",
    "            ncdata[k]['BB_SW']  = BBrefl[3]\n",
    "            \n",
    "            # uncertainty\n",
    "            #BBweight = np.dot(BBweights[:,:-1],ncdata[k]['weight'])\n",
    "            for b1,band1 in enumerate(['VIS','VIS_DIR','NIR','SW']):\n",
    "                for b2,band2 in enumerate(['VIS','VIS_DIR','NIR','SW']):\n",
    "                    if b2 <= b1:\n",
    "                        term = 'weight_BB_%s_%s'%(band1,band2)\n",
    "                        ncdata[k][term] = BBuncertainty_weight[b1,b2]\n",
    "\n",
    "            # extract qa\n",
    "            test = np.array(ncdata[k]['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze()\n",
    "            import pdb;pdb.set_trace()\n",
    "            test2 = np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_state_1km']).squeeze()\n",
    "            ncdata[k]['mask'] = modis_qa(test,good4=[0,8])\n",
    "            ncdata[k]['mask_snow'] = modis_qa2(test2,snow=True)\n",
    "            ncdata[k]['mask_nosnow'] = modis_qa2(test2,snow=False)\n",
    "            # obscov - use as a weighting term?\n",
    "            ncdata[k]['obscov'] = 0.01*np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_obscov_500m']).squeeze().astype(float)\n",
    "\n",
    "            # angles\n",
    "            vza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorZenith']).squeeze().astype(float)\n",
    "            sza = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarZenith']).squeeze().astype(float)\n",
    "            vaa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SensorAzimuth']).squeeze().astype(float)\n",
    "            saa = 0.01*np.array(ncdata[k]['MODIS_Grid_1km_2D_Data_Fields_SolarAzimuth']).squeeze().astype(float)\n",
    "            kern = kernels.Kernels(vza, sza, vaa-saa, doIntegrals=False, RossHS=False, RossType='Thick',\\\n",
    "                     LiType='Sparse', normalise=1, nbar=0., RecipFlag=True, MODISSPARSE=True)\n",
    "\n",
    "            ncdata[k]['Kvol'],ncdata[k]['Kgeo'] = np.asarray(kern.Ross),np.asarray(kern.Li)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine MODIS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the MODIS broad band reflectance data.\n",
    "\n",
    "We can look in particular at whether the two formulae given by Liang for direct and diffuse effects make any real difference.\n",
    "\n",
    "We can also examine the quality and quantity of snow and no snow data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR','NIR','SW']\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for mod in ['mod09']:\n",
    "    for i in xrange(4):\n",
    "        mm = ncdata[mod]['mask_snow']\n",
    "        x = ncdata[mod]['date'][mm]\n",
    "        y = ncdata[mod]['BB_%s'%bands[i]][mm]\n",
    "        w = ncdata[mod]['weight_BB_%s_%s'%(bands[i],bands[i])]\n",
    "        unc =  np.sqrt(1/w)\n",
    "        print unc\n",
    "        plt.plot(x,y,'+',label=mod+bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('snow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR','NIR','SW']\n",
    "bands = ['NIR']\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "for i in xrange(len(bands)):\n",
    "    mm = ncdata['myd09']['mask_nosnow']\n",
    "    x = ncdata['myd09']['date'][mm]\n",
    "    y = ncdata['myd09']['BB_%s'%bands[i]][mm]\n",
    "    plt.plot(x,y,'+',label=bands[i])\n",
    "plt.xlabel('time')\n",
    "plt.xlabel('reflectance')\n",
    "plt.legend(loc='best')\n",
    "plt.title('myd no snow')\n",
    "print ncdata['myd09']['date'].shape,ncdata['myd09']['mask_snow'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR']\n",
    "mm = ncdata['myd09']['mask_nosnow']\n",
    "plt.figure(figsize=(7,7))\n",
    "y0 = ncdata['myd09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['myd09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "\n",
    "mm = ncdata['mod09']['mask_nosnow']\n",
    "y0 = ncdata['mod09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['mod09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "\n",
    "plt.xlabel('diffuse VIS')\n",
    "plt.ylabel('direct VIS')\n",
    "plt.legend(loc='best')\n",
    "plt.title('no snow')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = ['VIS','VIS_DIR']\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "mm = ncdata['myd09']['mask_snow']\n",
    "y0 = ncdata['myd09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['myd09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "\n",
    "mm = ncdata['mod09']['mask_snow']\n",
    "y0 = ncdata['mod09']['BB_%s'%bands[0]][mm]\n",
    "y1 = ncdata['mod09']['BB_%s'%bands[1]][mm]\n",
    "plt.plot(y0,y1,'+')\n",
    "print scipy.stats.linregress(y0,y1)\n",
    "plt.xlabel('diffuse VIS')\n",
    "plt.ylabel('direct VIS')\n",
    "plt.legend(loc='best')\n",
    "plt.title('snow')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa = 0b11\n",
    "\n",
    "np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze() & qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BBrefl = (np.dot(BBweights[:,:-1],ncdata['mod09']['reflectance']).T + BBweights[:,-1]).T\n",
    "print ncdata['mod09']['reflectance'].shape,BBrefl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 'mod09'\n",
    "for kk in ncdata[k].keys():\n",
    "    print kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yeardoy = np.array([ [int(str(i)[:4]),int(str(i)[4:])] for i in ncdata['mod09']['doy']])\n",
    "\n",
    "\n",
    "np.array(ncdata['mod09']['MODIS_Grid_500m_2D_Data_Fields_QC_500m']).squeeze().astype(np.uint32).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
